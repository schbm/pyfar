{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4785475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 16:49:14.196303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749221354.228076    5364 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749221354.238385    5364 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749221354.277554    5364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749221354.277573    5364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749221354.277575    5364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749221354.277577    5364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-06 16:49:14.290560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1749221357.572444    5364 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:0b:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from data import DataLoaderCifar\n",
    "import keras\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ab69ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1bda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoaderCifar(validation_dataset_size=5000, mini_batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410bdb93",
   "metadata": {},
   "source": [
    "## Check Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0360c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n",
      "(128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:43:02.985642: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = loader.train_dataset\n",
    "for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    print(x_batch_train.shape)\n",
    "    print(y_batch_train.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5826705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n",
      "(128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:43:05.359265: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = loader.valid_dataset\n",
    "for step, (x_batch_valid, y_batch_valid) in enumerate(valid_dataset):\n",
    "    print(x_batch_valid.shape)\n",
    "    print(y_batch_valid.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cbc17",
   "metadata": {},
   "source": [
    "# Dense Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4afeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Model without regularization\n",
    "def NewDenseModelCifar(depth, width):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
    "    \n",
    "    for i in range(depth):\n",
    "        model.add(keras.layers.Dense(width, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628101b7",
   "metadata": {},
   "source": [
    "# Testing Width\n",
    "Here we train models with different width and `depth = 1`.\n",
    "We set a high enough amount of epochs and use early stopping on the training loss\n",
    "to measure when a model is not able to reduce it any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0705c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with p=3157002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_29 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,157,002</span> (12.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,157,002\u001b[0m (12.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,157,002</span> (12.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,157,002\u001b[0m (12.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 14:31:46.805005: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_107', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-05-31 14:31:46.880183: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_107', 420 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "E0000 00:00:1748694707.094227    3237 buffer_comparator.cc:157] Difference at 134: 472.591, expected 527.828\n",
      "E0000 00:00:1748694707.094282    3237 buffer_comparator.cc:157] Difference at 160: 1.48627, expected 506.263\n",
      "E0000 00:00:1748694707.094290    3237 buffer_comparator.cc:157] Difference at 161: 1.65882, expected 527.144\n",
      "E0000 00:00:1748694707.094293    3237 buffer_comparator.cc:157] Difference at 162: 2.58824, expected 510.75\n",
      "E0000 00:00:1748694707.094296    3237 buffer_comparator.cc:157] Difference at 163: 1.60784, expected 517.278\n",
      "E0000 00:00:1748694707.094298    3237 buffer_comparator.cc:157] Difference at 164: 1.85882, expected 517.155\n",
      "E0000 00:00:1748694707.094300    3237 buffer_comparator.cc:157] Difference at 165: 2.55686, expected 512.279\n",
      "E0000 00:00:1748694707.094303    3237 buffer_comparator.cc:157] Difference at 166: 1.83137, expected 500.142\n",
      "E0000 00:00:1748694707.094305    3237 buffer_comparator.cc:157] Difference at 167: 2.26667, expected 493.326\n",
      "E0000 00:00:1748694707.094307    3237 buffer_comparator.cc:157] Difference at 168: 2.96078, expected 527.223\n",
      "2025-05-31 14:31:47.094316: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.104441    3237 buffer_comparator.cc:157] Difference at 2: 571.636, expected 510.433\n",
      "E0000 00:00:1748694707.104481    3237 buffer_comparator.cc:157] Difference at 6: 450.668, expected 506.885\n",
      "E0000 00:00:1748694707.104490    3237 buffer_comparator.cc:157] Difference at 8: 470.261, expected 523.17\n",
      "E0000 00:00:1748694707.104492    3237 buffer_comparator.cc:157] Difference at 10: 549.369, expected 493.943\n",
      "E0000 00:00:1748694707.104495    3237 buffer_comparator.cc:157] Difference at 12: 574.922, expected 509.112\n",
      "E0000 00:00:1748694707.104499    3237 buffer_comparator.cc:157] Difference at 28: 471.739, expected 525.581\n",
      "E0000 00:00:1748694707.104501    3237 buffer_comparator.cc:157] Difference at 36: 450.923, expected 503.83\n",
      "E0000 00:00:1748694707.104504    3237 buffer_comparator.cc:157] Difference at 46: 452.453, expected 504.927\n",
      "E0000 00:00:1748694707.104506    3237 buffer_comparator.cc:157] Difference at 48: 472.439, expected 525.363\n",
      "E0000 00:00:1748694707.104508    3237 buffer_comparator.cc:157] Difference at 56: 432.815, expected 501.043\n",
      "2025-05-31 14:31:47.104513: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.115098    3237 buffer_comparator.cc:157] Difference at 160: 4.58431, expected 506.263\n",
      "E0000 00:00:1748694707.115134    3237 buffer_comparator.cc:157] Difference at 161: 3.88235, expected 527.144\n",
      "E0000 00:00:1748694707.115142    3237 buffer_comparator.cc:157] Difference at 162: 4.7451, expected 510.75\n",
      "E0000 00:00:1748694707.115145    3237 buffer_comparator.cc:157] Difference at 163: 4.71373, expected 517.278\n",
      "E0000 00:00:1748694707.115147    3237 buffer_comparator.cc:157] Difference at 164: 4.07059, expected 517.155\n",
      "E0000 00:00:1748694707.115150    3237 buffer_comparator.cc:157] Difference at 165: 4.75686, expected 512.279\n",
      "E0000 00:00:1748694707.115152    3237 buffer_comparator.cc:157] Difference at 166: 4.98824, expected 500.142\n",
      "E0000 00:00:1748694707.115154    3237 buffer_comparator.cc:157] Difference at 167: 4.45882, expected 493.326\n",
      "E0000 00:00:1748694707.115156    3237 buffer_comparator.cc:157] Difference at 168: 5.12157, expected 527.223\n",
      "E0000 00:00:1748694707.115159    3237 buffer_comparator.cc:157] Difference at 169: 5.01569, expected 520.536\n",
      "2025-05-31 14:31:47.115163: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.122910    3237 buffer_comparator.cc:157] Difference at 160: 4.58431, expected 506.263\n",
      "E0000 00:00:1748694707.122946    3237 buffer_comparator.cc:157] Difference at 161: 3.88235, expected 527.144\n",
      "E0000 00:00:1748694707.122954    3237 buffer_comparator.cc:157] Difference at 162: 4.7451, expected 510.75\n",
      "E0000 00:00:1748694707.122956    3237 buffer_comparator.cc:157] Difference at 163: 4.71373, expected 517.278\n",
      "E0000 00:00:1748694707.122959    3237 buffer_comparator.cc:157] Difference at 164: 4.07059, expected 517.155\n",
      "E0000 00:00:1748694707.122961    3237 buffer_comparator.cc:157] Difference at 165: 4.75686, expected 512.279\n",
      "E0000 00:00:1748694707.122963    3237 buffer_comparator.cc:157] Difference at 166: 4.98824, expected 500.142\n",
      "E0000 00:00:1748694707.122965    3237 buffer_comparator.cc:157] Difference at 167: 4.45882, expected 493.326\n",
      "E0000 00:00:1748694707.122968    3237 buffer_comparator.cc:157] Difference at 168: 5.12157, expected 527.223\n",
      "E0000 00:00:1748694707.122970    3237 buffer_comparator.cc:157] Difference at 169: 5.01569, expected 520.536\n",
      "2025-05-31 14:31:47.122974: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.129817    3237 buffer_comparator.cc:157] Difference at 160: 4.58431, expected 506.263\n",
      "E0000 00:00:1748694707.129853    3237 buffer_comparator.cc:157] Difference at 161: 3.88235, expected 527.144\n",
      "E0000 00:00:1748694707.129861    3237 buffer_comparator.cc:157] Difference at 162: 4.7451, expected 510.75\n",
      "E0000 00:00:1748694707.129864    3237 buffer_comparator.cc:157] Difference at 163: 4.71373, expected 517.278\n",
      "E0000 00:00:1748694707.129866    3237 buffer_comparator.cc:157] Difference at 164: 4.07059, expected 517.155\n",
      "E0000 00:00:1748694707.129869    3237 buffer_comparator.cc:157] Difference at 165: 4.75686, expected 512.279\n",
      "E0000 00:00:1748694707.129871    3237 buffer_comparator.cc:157] Difference at 166: 4.98824, expected 500.142\n",
      "E0000 00:00:1748694707.129873    3237 buffer_comparator.cc:157] Difference at 167: 4.45882, expected 493.326\n",
      "E0000 00:00:1748694707.129875    3237 buffer_comparator.cc:157] Difference at 168: 5.12157, expected 527.223\n",
      "E0000 00:00:1748694707.129877    3237 buffer_comparator.cc:157] Difference at 169: 5.01569, expected 520.536\n",
      "2025-05-31 14:31:47.129882: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.140084    3237 buffer_comparator.cc:157] Difference at 320: 4.91765, expected 503.851\n",
      "E0000 00:00:1748694707.140120    3237 buffer_comparator.cc:157] Difference at 321: 5.54902, expected 532.659\n",
      "E0000 00:00:1748694707.140128    3237 buffer_comparator.cc:157] Difference at 322: 5.44314, expected 514.831\n",
      "E0000 00:00:1748694707.140131    3237 buffer_comparator.cc:157] Difference at 323: 4.99608, expected 514.616\n",
      "E0000 00:00:1748694707.140133    3237 buffer_comparator.cc:157] Difference at 324: 5.47059, expected 522.019\n",
      "E0000 00:00:1748694707.140136    3237 buffer_comparator.cc:157] Difference at 325: 5.74902, expected 516.227\n",
      "E0000 00:00:1748694707.140138    3237 buffer_comparator.cc:157] Difference at 326: 5.61569, expected 504.435\n",
      "E0000 00:00:1748694707.140140    3237 buffer_comparator.cc:157] Difference at 327: 5.81961, expected 501.711\n",
      "E0000 00:00:1748694707.140143    3237 buffer_comparator.cc:157] Difference at 328: 5.63529, expected 520.612\n",
      "E0000 00:00:1748694707.140145    3237 buffer_comparator.cc:157] Difference at 329: 5.68235, expected 519.736\n",
      "2025-05-31 14:31:47.140149: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.151211    3237 buffer_comparator.cc:157] Difference at 10: 556.261, expected 493.943\n",
      "E0000 00:00:1748694707.151248    3237 buffer_comparator.cc:157] Difference at 320: 0.792157, expected 503.851\n",
      "E0000 00:00:1748694707.151256    3237 buffer_comparator.cc:157] Difference at 321: 1.16078, expected 532.659\n",
      "E0000 00:00:1748694707.151259    3237 buffer_comparator.cc:157] Difference at 322: 1.15294, expected 514.831\n",
      "E0000 00:00:1748694707.151262    3237 buffer_comparator.cc:157] Difference at 323: 0.882353, expected 514.616\n",
      "E0000 00:00:1748694707.151265    3237 buffer_comparator.cc:157] Difference at 324: 1.1098, expected 522.019\n",
      "E0000 00:00:1748694707.151267    3237 buffer_comparator.cc:157] Difference at 325: 1.2549, expected 516.227\n",
      "E0000 00:00:1748694707.151269    3237 buffer_comparator.cc:157] Difference at 326: 1.04314, expected 504.435\n",
      "E0000 00:00:1748694707.151271    3237 buffer_comparator.cc:157] Difference at 327: 1.32941, expected 501.711\n",
      "E0000 00:00:1748694707.151274    3237 buffer_comparator.cc:157] Difference at 328: 1.41961, expected 520.612\n",
      "2025-05-31 14:31:47.151279: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.160684    3237 buffer_comparator.cc:157] Difference at 320: 0.792157, expected 503.851\n",
      "E0000 00:00:1748694707.160724    3237 buffer_comparator.cc:157] Difference at 321: 1.16078, expected 532.659\n",
      "E0000 00:00:1748694707.160732    3237 buffer_comparator.cc:157] Difference at 322: 1.15294, expected 514.831\n",
      "E0000 00:00:1748694707.160735    3237 buffer_comparator.cc:157] Difference at 323: 0.882353, expected 514.616\n",
      "E0000 00:00:1748694707.160737    3237 buffer_comparator.cc:157] Difference at 324: 1.1098, expected 522.019\n",
      "E0000 00:00:1748694707.160740    3237 buffer_comparator.cc:157] Difference at 325: 1.2549, expected 516.227\n",
      "E0000 00:00:1748694707.160743    3237 buffer_comparator.cc:157] Difference at 326: 1.04314, expected 504.435\n",
      "E0000 00:00:1748694707.160745    3237 buffer_comparator.cc:157] Difference at 327: 1.32941, expected 501.711\n",
      "E0000 00:00:1748694707.160747    3237 buffer_comparator.cc:157] Difference at 328: 1.41961, expected 520.612\n",
      "E0000 00:00:1748694707.160749    3237 buffer_comparator.cc:157] Difference at 329: 1.22353, expected 519.736\n",
      "2025-05-31 14:31:47.160754: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.167487    3237 buffer_comparator.cc:157] Difference at 640: 1.37647, expected 508.728\n",
      "E0000 00:00:1748694707.167535    3237 buffer_comparator.cc:157] Difference at 641: 1.51373, expected 535.181\n",
      "E0000 00:00:1748694707.167546    3237 buffer_comparator.cc:157] Difference at 642: 1.47059, expected 514.757\n",
      "E0000 00:00:1748694707.167550    3237 buffer_comparator.cc:157] Difference at 643: 1.16863, expected 516.797\n",
      "E0000 00:00:1748694707.167555    3237 buffer_comparator.cc:157] Difference at 644: 1.57255, expected 525.881\n",
      "E0000 00:00:1748694707.167559    3237 buffer_comparator.cc:157] Difference at 645: 1.5098, expected 519.151\n",
      "E0000 00:00:1748694707.167563    3237 buffer_comparator.cc:157] Difference at 646: 0.941176, expected 505.505\n",
      "E0000 00:00:1748694707.167566    3237 buffer_comparator.cc:157] Difference at 647: 1.51765, expected 508.803\n",
      "E0000 00:00:1748694707.167568    3237 buffer_comparator.cc:157] Difference at 648: 1.42353, expected 525.912\n",
      "E0000 00:00:1748694707.167570    3237 buffer_comparator.cc:157] Difference at 649: 0.917647, expected 523.243\n",
      "2025-05-31 14:31:47.167575: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.175144    3237 buffer_comparator.cc:157] Difference at 2: 571.636, expected 510.433\n",
      "E0000 00:00:1748694707.175179    3237 buffer_comparator.cc:157] Difference at 6: 450.668, expected 506.885\n",
      "E0000 00:00:1748694707.175188    3237 buffer_comparator.cc:157] Difference at 8: 470.261, expected 523.17\n",
      "E0000 00:00:1748694707.175191    3237 buffer_comparator.cc:157] Difference at 10: 549.369, expected 493.943\n",
      "E0000 00:00:1748694707.175194    3237 buffer_comparator.cc:157] Difference at 12: 574.922, expected 509.112\n",
      "E0000 00:00:1748694707.175197    3237 buffer_comparator.cc:157] Difference at 28: 471.739, expected 525.581\n",
      "E0000 00:00:1748694707.175199    3237 buffer_comparator.cc:157] Difference at 36: 450.923, expected 503.83\n",
      "E0000 00:00:1748694707.175201    3237 buffer_comparator.cc:157] Difference at 46: 452.453, expected 504.927\n",
      "E0000 00:00:1748694707.175204    3237 buffer_comparator.cc:157] Difference at 48: 472.439, expected 525.363\n",
      "E0000 00:00:1748694707.175206    3237 buffer_comparator.cc:157] Difference at 56: 432.815, expected 501.043\n",
      "2025-05-31 14:31:47.175211: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.182900    3237 buffer_comparator.cc:157] Difference at 640: 5.29412, expected 508.728\n",
      "E0000 00:00:1748694707.182934    3237 buffer_comparator.cc:157] Difference at 641: 4.96863, expected 535.181\n",
      "E0000 00:00:1748694707.182943    3237 buffer_comparator.cc:157] Difference at 642: 5.45882, expected 514.757\n",
      "E0000 00:00:1748694707.182945    3237 buffer_comparator.cc:157] Difference at 643: 4.98039, expected 516.797\n",
      "E0000 00:00:1748694707.182947    3237 buffer_comparator.cc:157] Difference at 644: 5.11373, expected 525.881\n",
      "E0000 00:00:1748694707.182951    3237 buffer_comparator.cc:157] Difference at 645: 5.58039, expected 519.151\n",
      "E0000 00:00:1748694707.182953    3237 buffer_comparator.cc:157] Difference at 646: 4.61569, expected 505.505\n",
      "E0000 00:00:1748694707.182955    3237 buffer_comparator.cc:157] Difference at 647: 5.12941, expected 508.803\n",
      "E0000 00:00:1748694707.182957    3237 buffer_comparator.cc:157] Difference at 648: 5.32157, expected 525.912\n",
      "E0000 00:00:1748694707.182959    3237 buffer_comparator.cc:157] Difference at 649: 4.93726, expected 523.243\n",
      "2025-05-31 14:31:47.182964: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.188731    3237 buffer_comparator.cc:157] Difference at 640: 5.29412, expected 508.728\n",
      "E0000 00:00:1748694707.188766    3237 buffer_comparator.cc:157] Difference at 641: 4.96863, expected 535.181\n",
      "E0000 00:00:1748694707.188775    3237 buffer_comparator.cc:157] Difference at 642: 5.45882, expected 514.757\n",
      "E0000 00:00:1748694707.188777    3237 buffer_comparator.cc:157] Difference at 643: 4.98039, expected 516.797\n",
      "E0000 00:00:1748694707.188779    3237 buffer_comparator.cc:157] Difference at 644: 5.11373, expected 525.881\n",
      "E0000 00:00:1748694707.188781    3237 buffer_comparator.cc:157] Difference at 645: 5.58039, expected 519.151\n",
      "E0000 00:00:1748694707.188784    3237 buffer_comparator.cc:157] Difference at 646: 4.61569, expected 505.505\n",
      "E0000 00:00:1748694707.188786    3237 buffer_comparator.cc:157] Difference at 647: 5.12941, expected 508.803\n",
      "E0000 00:00:1748694707.188788    3237 buffer_comparator.cc:157] Difference at 648: 5.32157, expected 525.912\n",
      "E0000 00:00:1748694707.188790    3237 buffer_comparator.cc:157] Difference at 649: 4.93726, expected 523.243\n",
      "2025-05-31 14:31:47.188795: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.196061    3237 buffer_comparator.cc:157] Difference at 640: 5.29412, expected 508.728\n",
      "E0000 00:00:1748694707.196094    3237 buffer_comparator.cc:157] Difference at 641: 4.96863, expected 535.181\n",
      "E0000 00:00:1748694707.196102    3237 buffer_comparator.cc:157] Difference at 642: 5.45882, expected 514.757\n",
      "E0000 00:00:1748694707.196105    3237 buffer_comparator.cc:157] Difference at 643: 4.98039, expected 516.797\n",
      "E0000 00:00:1748694707.196108    3237 buffer_comparator.cc:157] Difference at 644: 5.11373, expected 525.881\n",
      "E0000 00:00:1748694707.196110    3237 buffer_comparator.cc:157] Difference at 645: 5.58039, expected 519.151\n",
      "E0000 00:00:1748694707.196112    3237 buffer_comparator.cc:157] Difference at 646: 4.61569, expected 505.505\n",
      "E0000 00:00:1748694707.196114    3237 buffer_comparator.cc:157] Difference at 647: 5.12941, expected 508.803\n",
      "E0000 00:00:1748694707.196116    3237 buffer_comparator.cc:157] Difference at 648: 5.32157, expected 525.912\n",
      "E0000 00:00:1748694707.196119    3237 buffer_comparator.cc:157] Difference at 649: 4.93726, expected 523.243\n",
      "2025-05-31 14:31:47.196123: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.234277    3237 buffer_comparator.cc:157] Difference at 10: 556.261, expected 493.943\n",
      "E0000 00:00:1748694707.234313    3237 buffer_comparator.cc:157] Difference at 964: 459.825, expected 512.446\n",
      "2025-05-31 14:31:47.234324: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.240071    3237 buffer_comparator.cc:157] Difference at 16: 0.615686, expected 0.0220644\n",
      "E0000 00:00:1748694707.240110    3237 buffer_comparator.cc:157] Difference at 17: 0.490196, expected 0.0192428\n",
      "E0000 00:00:1748694707.240118    3237 buffer_comparator.cc:157] Difference at 18: 0.509804, expected 0.0207534\n",
      "E0000 00:00:1748694707.240121    3237 buffer_comparator.cc:157] Difference at 19: 0.603922, expected 0.0168603\n",
      "E0000 00:00:1748694707.240123    3237 buffer_comparator.cc:157] Difference at 20: 0.470588, expected 0.0135947\n",
      "E0000 00:00:1748694707.240125    3237 buffer_comparator.cc:157] Difference at 21: 0.478431, expected 0.0226117\n",
      "E0000 00:00:1748694707.240128    3237 buffer_comparator.cc:157] Difference at 22: 0.6, expected 0.0161169\n",
      "E0000 00:00:1748694707.240130    3237 buffer_comparator.cc:157] Difference at 23: 0.466667, expected 0.0190103\n",
      "E0000 00:00:1748694707.240132    3237 buffer_comparator.cc:157] Difference at 24: 0.470588, expected 0.0253234\n",
      "E0000 00:00:1748694707.240134    3237 buffer_comparator.cc:157] Difference at 25: 0.611765, expected 0.0185718\n",
      "2025-05-31 14:31:47.240139: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.247714    3237 buffer_comparator.cc:157] Difference at 16: 0.615686, expected 0.0220644\n",
      "E0000 00:00:1748694707.247757    3237 buffer_comparator.cc:157] Difference at 17: 0.490196, expected 0.0192428\n",
      "E0000 00:00:1748694707.247765    3237 buffer_comparator.cc:157] Difference at 18: 0.509804, expected 0.0207534\n",
      "E0000 00:00:1748694707.247767    3237 buffer_comparator.cc:157] Difference at 19: 0.603922, expected 0.0168603\n",
      "E0000 00:00:1748694707.247769    3237 buffer_comparator.cc:157] Difference at 20: 0.470588, expected 0.0135947\n",
      "E0000 00:00:1748694707.247772    3237 buffer_comparator.cc:157] Difference at 21: 0.478431, expected 0.0226117\n",
      "E0000 00:00:1748694707.247774    3237 buffer_comparator.cc:157] Difference at 22: 0.6, expected 0.0161169\n",
      "E0000 00:00:1748694707.247776    3237 buffer_comparator.cc:157] Difference at 23: 0.466667, expected 0.0190103\n",
      "E0000 00:00:1748694707.247779    3237 buffer_comparator.cc:157] Difference at 24: 0.470588, expected 0.0253234\n",
      "E0000 00:00:1748694707.247781    3237 buffer_comparator.cc:157] Difference at 25: 0.611765, expected 0.0185718\n",
      "2025-05-31 14:31:47.247785: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.250387    3237 buffer_comparator.cc:157] Difference at 64: 0.705882, expected 0.0218191\n",
      "E0000 00:00:1748694707.250423    3237 buffer_comparator.cc:157] Difference at 65: 0.631373, expected 0.0147818\n",
      "E0000 00:00:1748694707.250431    3237 buffer_comparator.cc:157] Difference at 66: 0.662745, expected 0.025198\n",
      "E0000 00:00:1748694707.250434    3237 buffer_comparator.cc:157] Difference at 67: 0.690196, expected 0.0278996\n",
      "E0000 00:00:1748694707.250436    3237 buffer_comparator.cc:157] Difference at 68: 0.603922, expected 0.0202336\n",
      "E0000 00:00:1748694707.250438    3237 buffer_comparator.cc:157] Difference at 69: 0.631373, expected 0.0303191\n",
      "E0000 00:00:1748694707.250441    3237 buffer_comparator.cc:157] Difference at 70: 0.67451, expected 0.0253849\n",
      "E0000 00:00:1748694707.250443    3237 buffer_comparator.cc:157] Difference at 71: 0.564706, expected 0.0276733\n",
      "E0000 00:00:1748694707.250445    3237 buffer_comparator.cc:157] Difference at 72: 0.596078, expected 0.0276649\n",
      "E0000 00:00:1748694707.250447    3237 buffer_comparator.cc:157] Difference at 73: 0.666667, expected 0.0228823\n",
      "2025-05-31 14:31:47.250451: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.260434    3237 buffer_comparator.cc:157] Difference at 64: 0.705882, expected 0.0218191\n",
      "E0000 00:00:1748694707.260471    3237 buffer_comparator.cc:157] Difference at 65: 0.631373, expected 0.0147818\n",
      "E0000 00:00:1748694707.260479    3237 buffer_comparator.cc:157] Difference at 66: 0.662745, expected 0.025198\n",
      "E0000 00:00:1748694707.260482    3237 buffer_comparator.cc:157] Difference at 67: 0.690196, expected 0.0278996\n",
      "E0000 00:00:1748694707.260485    3237 buffer_comparator.cc:157] Difference at 68: 0.603922, expected 0.0202336\n",
      "E0000 00:00:1748694707.260487    3237 buffer_comparator.cc:157] Difference at 69: 0.631373, expected 0.0303191\n",
      "E0000 00:00:1748694707.260489    3237 buffer_comparator.cc:157] Difference at 70: 0.67451, expected 0.0253849\n",
      "E0000 00:00:1748694707.260491    3237 buffer_comparator.cc:157] Difference at 71: 0.564706, expected 0.0276733\n",
      "E0000 00:00:1748694707.260493    3237 buffer_comparator.cc:157] Difference at 72: 0.596078, expected 0.0276649\n",
      "E0000 00:00:1748694707.260495    3237 buffer_comparator.cc:157] Difference at 73: 0.666667, expected 0.0228823\n",
      "2025-05-31 14:31:47.260500: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.264693    3237 buffer_comparator.cc:157] Difference at 64: 0.705882, expected 0.0218191\n",
      "E0000 00:00:1748694707.264736    3237 buffer_comparator.cc:157] Difference at 65: 0.631373, expected 0.0147818\n",
      "E0000 00:00:1748694707.264744    3237 buffer_comparator.cc:157] Difference at 66: 0.662745, expected 0.025198\n",
      "E0000 00:00:1748694707.264746    3237 buffer_comparator.cc:157] Difference at 67: 0.690196, expected 0.0278996\n",
      "E0000 00:00:1748694707.264748    3237 buffer_comparator.cc:157] Difference at 68: 0.603922, expected 0.0202336\n",
      "E0000 00:00:1748694707.264751    3237 buffer_comparator.cc:157] Difference at 69: 0.631373, expected 0.0303191\n",
      "E0000 00:00:1748694707.264753    3237 buffer_comparator.cc:157] Difference at 70: 0.67451, expected 0.0253849\n",
      "E0000 00:00:1748694707.264755    3237 buffer_comparator.cc:157] Difference at 71: 0.564706, expected 0.0276733\n",
      "E0000 00:00:1748694707.264757    3237 buffer_comparator.cc:157] Difference at 72: 0.596078, expected 0.0276649\n",
      "E0000 00:00:1748694707.264759    3237 buffer_comparator.cc:157] Difference at 73: 0.666667, expected 0.0228823\n",
      "2025-05-31 14:31:47.264764: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.274842    3237 buffer_comparator.cc:157] Difference at 128: 0.470588, expected 0.0263974\n",
      "E0000 00:00:1748694707.274889    3237 buffer_comparator.cc:157] Difference at 129: 0.454902, expected 0.0212705\n",
      "E0000 00:00:1748694707.274897    3237 buffer_comparator.cc:157] Difference at 130: 0.619608, expected 0.0324213\n",
      "E0000 00:00:1748694707.274901    3237 buffer_comparator.cc:157] Difference at 131: 0.470588, expected 0.0236753\n",
      "E0000 00:00:1748694707.274903    3237 buffer_comparator.cc:157] Difference at 132: 0.466667, expected 0.0240482\n",
      "E0000 00:00:1748694707.274905    3237 buffer_comparator.cc:157] Difference at 133: 0.596078, expected 0.0272265\n",
      "E0000 00:00:1748694707.274908    3237 buffer_comparator.cc:157] Difference at 134: 0.462745, expected 0.0267631\n",
      "E0000 00:00:1748694707.274910    3237 buffer_comparator.cc:157] Difference at 135: 0.458824, expected 0.0199839\n",
      "E0000 00:00:1748694707.274912    3237 buffer_comparator.cc:157] Difference at 136: 0.576471, expected 0.0242576\n",
      "E0000 00:00:1748694707.274914    3237 buffer_comparator.cc:157] Difference at 137: 0.454902, expected 0.0187152\n",
      "2025-05-31 14:31:47.274919: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.277940    3237 buffer_comparator.cc:157] Difference at 128: 0.470588, expected 0.0263974\n",
      "E0000 00:00:1748694707.277988    3237 buffer_comparator.cc:157] Difference at 129: 0.454902, expected 0.0212705\n",
      "E0000 00:00:1748694707.278001    3237 buffer_comparator.cc:157] Difference at 130: 0.619608, expected 0.0324213\n",
      "E0000 00:00:1748694707.278006    3237 buffer_comparator.cc:157] Difference at 131: 0.470588, expected 0.0236753\n",
      "E0000 00:00:1748694707.278018    3237 buffer_comparator.cc:157] Difference at 132: 0.466667, expected 0.0240482\n",
      "E0000 00:00:1748694707.278022    3237 buffer_comparator.cc:157] Difference at 133: 0.596078, expected 0.0272265\n",
      "E0000 00:00:1748694707.278024    3237 buffer_comparator.cc:157] Difference at 134: 0.462745, expected 0.0267631\n",
      "E0000 00:00:1748694707.278026    3237 buffer_comparator.cc:157] Difference at 135: 0.458824, expected 0.0199839\n",
      "E0000 00:00:1748694707.278028    3237 buffer_comparator.cc:157] Difference at 136: 0.576471, expected 0.0242576\n",
      "E0000 00:00:1748694707.278031    3237 buffer_comparator.cc:157] Difference at 137: 0.454902, expected 0.0187152\n",
      "2025-05-31 14:31:47.278044: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.288423    3237 buffer_comparator.cc:157] Difference at 128: 0.470588, expected 0.0263974\n",
      "E0000 00:00:1748694707.288460    3237 buffer_comparator.cc:157] Difference at 129: 0.454902, expected 0.0212705\n",
      "E0000 00:00:1748694707.288468    3237 buffer_comparator.cc:157] Difference at 130: 0.619608, expected 0.0324213\n",
      "E0000 00:00:1748694707.288470    3237 buffer_comparator.cc:157] Difference at 131: 0.470588, expected 0.0236753\n",
      "E0000 00:00:1748694707.288473    3237 buffer_comparator.cc:157] Difference at 132: 0.466667, expected 0.0240482\n",
      "E0000 00:00:1748694707.288475    3237 buffer_comparator.cc:157] Difference at 133: 0.596078, expected 0.0272265\n",
      "E0000 00:00:1748694707.288477    3237 buffer_comparator.cc:157] Difference at 134: 0.462745, expected 0.0267631\n",
      "E0000 00:00:1748694707.288479    3237 buffer_comparator.cc:157] Difference at 135: 0.458824, expected 0.0199839\n",
      "E0000 00:00:1748694707.288482    3237 buffer_comparator.cc:157] Difference at 136: 0.576471, expected 0.0242576\n",
      "E0000 00:00:1748694707.288484    3237 buffer_comparator.cc:157] Difference at 137: 0.454902, expected 0.0187152\n",
      "2025-05-31 14:31:47.288488: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.297108    3237 buffer_comparator.cc:157] Difference at 128: 0.470588, expected 0.0263974\n",
      "E0000 00:00:1748694707.297145    3237 buffer_comparator.cc:157] Difference at 129: 0.454902, expected 0.0212705\n",
      "E0000 00:00:1748694707.297154    3237 buffer_comparator.cc:157] Difference at 130: 0.619608, expected 0.0324213\n",
      "E0000 00:00:1748694707.297157    3237 buffer_comparator.cc:157] Difference at 131: 0.470588, expected 0.0236753\n",
      "E0000 00:00:1748694707.297160    3237 buffer_comparator.cc:157] Difference at 132: 0.466667, expected 0.0240482\n",
      "E0000 00:00:1748694707.297162    3237 buffer_comparator.cc:157] Difference at 133: 0.596078, expected 0.0272265\n",
      "E0000 00:00:1748694707.297164    3237 buffer_comparator.cc:157] Difference at 134: 0.462745, expected 0.0267631\n",
      "E0000 00:00:1748694707.297166    3237 buffer_comparator.cc:157] Difference at 135: 0.458824, expected 0.0199839\n",
      "E0000 00:00:1748694707.297168    3237 buffer_comparator.cc:157] Difference at 136: 0.576471, expected 0.0242576\n",
      "E0000 00:00:1748694707.297170    3237 buffer_comparator.cc:157] Difference at 137: 0.454902, expected 0.0187152\n",
      "2025-05-31 14:31:47.297175: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.300396    3237 buffer_comparator.cc:157] Difference at 128: 0.470588, expected 0.0263974\n",
      "E0000 00:00:1748694707.300434    3237 buffer_comparator.cc:157] Difference at 129: 0.454902, expected 0.0212705\n",
      "E0000 00:00:1748694707.300442    3237 buffer_comparator.cc:157] Difference at 130: 0.619608, expected 0.0324213\n",
      "E0000 00:00:1748694707.300444    3237 buffer_comparator.cc:157] Difference at 131: 0.470588, expected 0.0236753\n",
      "E0000 00:00:1748694707.300447    3237 buffer_comparator.cc:157] Difference at 132: 0.466667, expected 0.0240482\n",
      "E0000 00:00:1748694707.300449    3237 buffer_comparator.cc:157] Difference at 133: 0.596078, expected 0.0272265\n",
      "E0000 00:00:1748694707.300451    3237 buffer_comparator.cc:157] Difference at 134: 0.462745, expected 0.0267631\n",
      "E0000 00:00:1748694707.300453    3237 buffer_comparator.cc:157] Difference at 135: 0.458824, expected 0.0199839\n",
      "E0000 00:00:1748694707.300455    3237 buffer_comparator.cc:157] Difference at 136: 0.576471, expected 0.0242576\n",
      "E0000 00:00:1748694707.300458    3237 buffer_comparator.cc:157] Difference at 137: 0.454902, expected 0.0187152\n",
      "2025-05-31 14:31:47.300462: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.308755    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.308798    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.308806    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.308808    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.308812    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.308814    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.308816    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.308818    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.308820    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.308822    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.308828: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.311429    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.311468    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.311476    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.311479    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.311481    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.311483    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.311485    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.311488    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.311490    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.311492    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.311497: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.312541    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.312577    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.312585    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.312588    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.312590    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.312592    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.312595    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.312597    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.312599    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.312601    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.312606: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.313442    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.313476    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.313485    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.313487    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.313489    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.313492    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.313494    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.313496    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.313498    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.313500    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.313505: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.314572    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.314612    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.314620    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.314623    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.314626    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.314628    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.314630    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.314632    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.314634    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.314636    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.314641: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.316095    3237 buffer_comparator.cc:157] Difference at 256: 0.654902, expected 0.0265455\n",
      "E0000 00:00:1748694707.316130    3237 buffer_comparator.cc:157] Difference at 257: 0.537255, expected 0.0227402\n",
      "E0000 00:00:1748694707.316138    3237 buffer_comparator.cc:157] Difference at 258: 0.556863, expected 0.0205645\n",
      "E0000 00:00:1748694707.316141    3237 buffer_comparator.cc:157] Difference at 259: 0.658824, expected 0.0155351\n",
      "E0000 00:00:1748694707.316143    3237 buffer_comparator.cc:157] Difference at 260: 0.54902, expected 0.0152106\n",
      "E0000 00:00:1748694707.316145    3237 buffer_comparator.cc:157] Difference at 261: 0.568627, expected 0.0249682\n",
      "E0000 00:00:1748694707.316148    3237 buffer_comparator.cc:157] Difference at 262: 0.678431, expected 0.0276197\n",
      "E0000 00:00:1748694707.316150    3237 buffer_comparator.cc:157] Difference at 263: 0.580392, expected 0.0200536\n",
      "E0000 00:00:1748694707.316152    3237 buffer_comparator.cc:157] Difference at 264: 0.6, expected 0.0269704\n",
      "E0000 00:00:1748694707.316154    3237 buffer_comparator.cc:157] Difference at 265: 0.717647, expected 0.0188563\n",
      "2025-05-31 14:31:47.316159: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.317572    3237 buffer_comparator.cc:157] Difference at 160: 0.0158704, expected 0.33457\n",
      "E0000 00:00:1748694707.317600    3237 buffer_comparator.cc:157] Difference at 161: 0.018586, expected 0.341828\n",
      "E0000 00:00:1748694707.317609    3237 buffer_comparator.cc:157] Difference at 162: 0.0131546, expected 0.349567\n",
      "E0000 00:00:1748694707.317611    3237 buffer_comparator.cc:157] Difference at 163: 0.0143314, expected 0.304546\n",
      "E0000 00:00:1748694707.317614    3237 buffer_comparator.cc:157] Difference at 164: 0.0144472, expected 0.342132\n",
      "E0000 00:00:1748694707.317616    3237 buffer_comparator.cc:157] Difference at 165: 0.0232167, expected 0.337053\n",
      "E0000 00:00:1748694707.317618    3237 buffer_comparator.cc:157] Difference at 166: 0.018783, expected 0.305482\n",
      "E0000 00:00:1748694707.317620    3237 buffer_comparator.cc:157] Difference at 167: 0.0180008, expected 0.331525\n",
      "E0000 00:00:1748694707.317623    3237 buffer_comparator.cc:157] Difference at 168: 0.0167188, expected 0.337232\n",
      "E0000 00:00:1748694707.317625    3237 buffer_comparator.cc:157] Difference at 169: 0.0206504, expected 0.346607\n",
      "2025-05-31 14:31:47.317629: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.318410    3237 buffer_comparator.cc:157] Difference at 160: 0.0158704, expected 0.33457\n",
      "E0000 00:00:1748694707.318443    3237 buffer_comparator.cc:157] Difference at 161: 0.018586, expected 0.341828\n",
      "E0000 00:00:1748694707.318451    3237 buffer_comparator.cc:157] Difference at 162: 0.0131546, expected 0.349567\n",
      "E0000 00:00:1748694707.318454    3237 buffer_comparator.cc:157] Difference at 163: 0.0143314, expected 0.304546\n",
      "E0000 00:00:1748694707.318456    3237 buffer_comparator.cc:157] Difference at 164: 0.0144472, expected 0.342132\n",
      "E0000 00:00:1748694707.318458    3237 buffer_comparator.cc:157] Difference at 165: 0.0232167, expected 0.337053\n",
      "E0000 00:00:1748694707.318460    3237 buffer_comparator.cc:157] Difference at 166: 0.018783, expected 0.305482\n",
      "E0000 00:00:1748694707.318462    3237 buffer_comparator.cc:157] Difference at 167: 0.0180008, expected 0.331525\n",
      "E0000 00:00:1748694707.318465    3237 buffer_comparator.cc:157] Difference at 168: 0.0167188, expected 0.337232\n",
      "E0000 00:00:1748694707.318467    3237 buffer_comparator.cc:157] Difference at 169: 0.0206504, expected 0.346607\n",
      "2025-05-31 14:31:47.318471: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.319277    3237 buffer_comparator.cc:157] Difference at 320: 0.0237411, expected 0.568411\n",
      "E0000 00:00:1748694707.319305    3237 buffer_comparator.cc:157] Difference at 321: 0.0121873, expected 0.555595\n",
      "E0000 00:00:1748694707.319313    3237 buffer_comparator.cc:157] Difference at 322: 0.0125194, expected 0.562055\n",
      "E0000 00:00:1748694707.319315    3237 buffer_comparator.cc:157] Difference at 323: 0.0199719, expected 0.51088\n",
      "E0000 00:00:1748694707.319318    3237 buffer_comparator.cc:157] Difference at 324: 0.0177024, expected 0.569668\n",
      "E0000 00:00:1748694707.319320    3237 buffer_comparator.cc:157] Difference at 325: 0.015071, expected 0.527608\n",
      "E0000 00:00:1748694707.319322    3237 buffer_comparator.cc:157] Difference at 326: 0.0234386, expected 0.506424\n",
      "E0000 00:00:1748694707.319324    3237 buffer_comparator.cc:157] Difference at 327: 0.0180202, expected 0.556427\n",
      "E0000 00:00:1748694707.319326    3237 buffer_comparator.cc:157] Difference at 328: 0.0152289, expected 0.550019\n",
      "E0000 00:00:1748694707.319329    3237 buffer_comparator.cc:157] Difference at 329: 0.0172872, expected 0.553659\n",
      "2025-05-31 14:31:47.319333: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.320085    3237 buffer_comparator.cc:157] Difference at 320: 0.0237411, expected 0.568411\n",
      "E0000 00:00:1748694707.320112    3237 buffer_comparator.cc:157] Difference at 321: 0.0121873, expected 0.555595\n",
      "E0000 00:00:1748694707.320120    3237 buffer_comparator.cc:157] Difference at 322: 0.0125194, expected 0.562055\n",
      "E0000 00:00:1748694707.320123    3237 buffer_comparator.cc:157] Difference at 323: 0.0199719, expected 0.51088\n",
      "E0000 00:00:1748694707.320125    3237 buffer_comparator.cc:157] Difference at 324: 0.0177024, expected 0.569668\n",
      "E0000 00:00:1748694707.320127    3237 buffer_comparator.cc:157] Difference at 325: 0.015071, expected 0.527608\n",
      "E0000 00:00:1748694707.320130    3237 buffer_comparator.cc:157] Difference at 326: 0.0234386, expected 0.506424\n",
      "E0000 00:00:1748694707.320132    3237 buffer_comparator.cc:157] Difference at 327: 0.0180202, expected 0.556427\n",
      "E0000 00:00:1748694707.320134    3237 buffer_comparator.cc:157] Difference at 328: 0.0152289, expected 0.550019\n",
      "E0000 00:00:1748694707.320136    3237 buffer_comparator.cc:157] Difference at 329: 0.0172872, expected 0.553659\n",
      "2025-05-31 14:31:47.320140: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.321004    3237 buffer_comparator.cc:157] Difference at 640: 0.017018, expected 0.559466\n",
      "E0000 00:00:1748694707.321032    3237 buffer_comparator.cc:157] Difference at 641: 0.0185511, expected 0.55442\n",
      "E0000 00:00:1748694707.321040    3237 buffer_comparator.cc:157] Difference at 642: 0.0139452, expected 0.577334\n",
      "E0000 00:00:1748694707.321042    3237 buffer_comparator.cc:157] Difference at 643: 0.0142715, expected 0.486778\n",
      "E0000 00:00:1748694707.321045    3237 buffer_comparator.cc:157] Difference at 644: 0.0174731, expected 0.578496\n",
      "E0000 00:00:1748694707.321047    3237 buffer_comparator.cc:157] Difference at 645: 0.0249758, expected 0.533548\n",
      "E0000 00:00:1748694707.321049    3237 buffer_comparator.cc:157] Difference at 646: 0.0179898, expected 0.500968\n",
      "E0000 00:00:1748694707.321051    3237 buffer_comparator.cc:157] Difference at 647: 0.0195687, expected 0.55783\n",
      "E0000 00:00:1748694707.321053    3237 buffer_comparator.cc:157] Difference at 648: 0.0132441, expected 0.560182\n",
      "E0000 00:00:1748694707.321056    3237 buffer_comparator.cc:157] Difference at 649: 0.0128845, expected 0.550122\n",
      "2025-05-31 14:31:47.321060: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.321828    3237 buffer_comparator.cc:157] Difference at 640: 0.017018, expected 0.559466\n",
      "E0000 00:00:1748694707.321855    3237 buffer_comparator.cc:157] Difference at 641: 0.0185511, expected 0.55442\n",
      "E0000 00:00:1748694707.321863    3237 buffer_comparator.cc:157] Difference at 642: 0.0139452, expected 0.577334\n",
      "E0000 00:00:1748694707.321866    3237 buffer_comparator.cc:157] Difference at 643: 0.0142715, expected 0.486778\n",
      "E0000 00:00:1748694707.321868    3237 buffer_comparator.cc:157] Difference at 644: 0.0174731, expected 0.578496\n",
      "E0000 00:00:1748694707.321870    3237 buffer_comparator.cc:157] Difference at 645: 0.0249758, expected 0.533548\n",
      "E0000 00:00:1748694707.321872    3237 buffer_comparator.cc:157] Difference at 646: 0.0179898, expected 0.500968\n",
      "E0000 00:00:1748694707.321874    3237 buffer_comparator.cc:157] Difference at 647: 0.0195687, expected 0.55783\n",
      "E0000 00:00:1748694707.321877    3237 buffer_comparator.cc:157] Difference at 648: 0.0132441, expected 0.560182\n",
      "E0000 00:00:1748694707.321879    3237 buffer_comparator.cc:157] Difference at 649: 0.0128845, expected 0.550122\n",
      "2025-05-31 14:31:47.321883: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.322705    3237 buffer_comparator.cc:157] Difference at 640: 0.017018, expected 0.559466\n",
      "E0000 00:00:1748694707.322733    3237 buffer_comparator.cc:157] Difference at 641: 0.0185511, expected 0.55442\n",
      "E0000 00:00:1748694707.322741    3237 buffer_comparator.cc:157] Difference at 642: 0.0139452, expected 0.577334\n",
      "E0000 00:00:1748694707.322744    3237 buffer_comparator.cc:157] Difference at 643: 0.0142715, expected 0.486778\n",
      "E0000 00:00:1748694707.322746    3237 buffer_comparator.cc:157] Difference at 644: 0.0174731, expected 0.578496\n",
      "E0000 00:00:1748694707.322748    3237 buffer_comparator.cc:157] Difference at 645: 0.0249758, expected 0.533548\n",
      "E0000 00:00:1748694707.322750    3237 buffer_comparator.cc:157] Difference at 646: 0.0179898, expected 0.500968\n",
      "E0000 00:00:1748694707.322753    3237 buffer_comparator.cc:157] Difference at 647: 0.0195687, expected 0.55783\n",
      "E0000 00:00:1748694707.322755    3237 buffer_comparator.cc:157] Difference at 648: 0.0132441, expected 0.560182\n",
      "E0000 00:00:1748694707.322757    3237 buffer_comparator.cc:157] Difference at 649: 0.0128845, expected 0.550122\n",
      "2025-05-31 14:31:47.322761: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.323571    3237 buffer_comparator.cc:157] Difference at 640: 0.017018, expected 0.559466\n",
      "E0000 00:00:1748694707.323598    3237 buffer_comparator.cc:157] Difference at 641: 0.0185511, expected 0.55442\n",
      "E0000 00:00:1748694707.323607    3237 buffer_comparator.cc:157] Difference at 642: 0.0139452, expected 0.577334\n",
      "E0000 00:00:1748694707.323609    3237 buffer_comparator.cc:157] Difference at 643: 0.0142715, expected 0.486778\n",
      "E0000 00:00:1748694707.323611    3237 buffer_comparator.cc:157] Difference at 644: 0.0174731, expected 0.578496\n",
      "E0000 00:00:1748694707.323614    3237 buffer_comparator.cc:157] Difference at 645: 0.0249758, expected 0.533548\n",
      "E0000 00:00:1748694707.323616    3237 buffer_comparator.cc:157] Difference at 646: 0.0179898, expected 0.500968\n",
      "E0000 00:00:1748694707.323618    3237 buffer_comparator.cc:157] Difference at 647: 0.0195687, expected 0.55783\n",
      "E0000 00:00:1748694707.323620    3237 buffer_comparator.cc:157] Difference at 648: 0.0132441, expected 0.560182\n",
      "E0000 00:00:1748694707.323622    3237 buffer_comparator.cc:157] Difference at 649: 0.0128845, expected 0.550122\n",
      "2025-05-31 14:31:47.323626: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.324421    3237 buffer_comparator.cc:157] Difference at 640: 0.017018, expected 0.559466\n",
      "E0000 00:00:1748694707.324448    3237 buffer_comparator.cc:157] Difference at 641: 0.0185511, expected 0.55442\n",
      "E0000 00:00:1748694707.324456    3237 buffer_comparator.cc:157] Difference at 642: 0.0139452, expected 0.577334\n",
      "E0000 00:00:1748694707.324459    3237 buffer_comparator.cc:157] Difference at 643: 0.0142715, expected 0.486778\n",
      "E0000 00:00:1748694707.324461    3237 buffer_comparator.cc:157] Difference at 644: 0.0174731, expected 0.578496\n",
      "E0000 00:00:1748694707.324463    3237 buffer_comparator.cc:157] Difference at 645: 0.0249758, expected 0.533548\n",
      "E0000 00:00:1748694707.324465    3237 buffer_comparator.cc:157] Difference at 646: 0.0179898, expected 0.500968\n",
      "E0000 00:00:1748694707.324467    3237 buffer_comparator.cc:157] Difference at 647: 0.0195687, expected 0.55783\n",
      "E0000 00:00:1748694707.324469    3237 buffer_comparator.cc:157] Difference at 648: 0.0132441, expected 0.560182\n",
      "E0000 00:00:1748694707.324471    3237 buffer_comparator.cc:157] Difference at 649: 0.0128845, expected 0.550122\n",
      "2025-05-31 14:31:47.324476: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.325287    3237 buffer_comparator.cc:157] Difference at 1280: 0.0264796, expected 0.685772\n",
      "E0000 00:00:1748694707.325314    3237 buffer_comparator.cc:157] Difference at 1281: 0.0214329, expected 0.695207\n",
      "E0000 00:00:1748694707.325323    3237 buffer_comparator.cc:157] Difference at 1282: 0.0259443, expected 0.70036\n",
      "E0000 00:00:1748694707.325326    3237 buffer_comparator.cc:157] Difference at 1283: 0.0198531, expected 0.608521\n",
      "E0000 00:00:1748694707.325328    3237 buffer_comparator.cc:157] Difference at 1284: 0.0184693, expected 0.694442\n",
      "E0000 00:00:1748694707.325330    3237 buffer_comparator.cc:157] Difference at 1285: 0.0247279, expected 0.645032\n",
      "E0000 00:00:1748694707.325332    3237 buffer_comparator.cc:157] Difference at 1286: 0.0265978, expected 0.614836\n",
      "E0000 00:00:1748694707.325334    3237 buffer_comparator.cc:157] Difference at 1287: 0.0174447, expected 0.686831\n",
      "E0000 00:00:1748694707.325336    3237 buffer_comparator.cc:157] Difference at 1288: 0.0251527, expected 0.686122\n",
      "E0000 00:00:1748694707.325339    3237 buffer_comparator.cc:157] Difference at 1289: 0.0198277, expected 0.69392\n",
      "2025-05-31 14:31:47.325343: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.326602    3237 buffer_comparator.cc:157] Difference at 1280: 0.0264796, expected 0.685772\n",
      "E0000 00:00:1748694707.326633    3237 buffer_comparator.cc:157] Difference at 1281: 0.0214329, expected 0.695207\n",
      "E0000 00:00:1748694707.326642    3237 buffer_comparator.cc:157] Difference at 1282: 0.0259443, expected 0.70036\n",
      "E0000 00:00:1748694707.326648    3237 buffer_comparator.cc:157] Difference at 1283: 0.0198531, expected 0.608521\n",
      "E0000 00:00:1748694707.326652    3237 buffer_comparator.cc:157] Difference at 1284: 0.0184693, expected 0.694442\n",
      "E0000 00:00:1748694707.326656    3237 buffer_comparator.cc:157] Difference at 1285: 0.0247279, expected 0.645032\n",
      "E0000 00:00:1748694707.326659    3237 buffer_comparator.cc:157] Difference at 1286: 0.0265978, expected 0.614836\n",
      "E0000 00:00:1748694707.326661    3237 buffer_comparator.cc:157] Difference at 1287: 0.0174447, expected 0.686831\n",
      "E0000 00:00:1748694707.326663    3237 buffer_comparator.cc:157] Difference at 1288: 0.0251527, expected 0.686122\n",
      "E0000 00:00:1748694707.326666    3237 buffer_comparator.cc:157] Difference at 1289: 0.0198277, expected 0.69392\n",
      "2025-05-31 14:31:47.326670: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.327835    3237 buffer_comparator.cc:157] Difference at 1280: 0.0445944, expected 0.685772\n",
      "E0000 00:00:1748694707.327865    3237 buffer_comparator.cc:157] Difference at 1281: 0.0371115, expected 0.695207\n",
      "E0000 00:00:1748694707.327873    3237 buffer_comparator.cc:157] Difference at 1282: 0.0349444, expected 0.70036\n",
      "E0000 00:00:1748694707.327877    3237 buffer_comparator.cc:157] Difference at 1283: 0.0367766, expected 0.608521\n",
      "E0000 00:00:1748694707.327879    3237 buffer_comparator.cc:157] Difference at 1284: 0.0346433, expected 0.694442\n",
      "E0000 00:00:1748694707.327881    3237 buffer_comparator.cc:157] Difference at 1285: 0.0464954, expected 0.645032\n",
      "E0000 00:00:1748694707.327883    3237 buffer_comparator.cc:157] Difference at 1286: 0.0464664, expected 0.614836\n",
      "E0000 00:00:1748694707.327885    3237 buffer_comparator.cc:157] Difference at 1287: 0.0323101, expected 0.686831\n",
      "E0000 00:00:1748694707.327888    3237 buffer_comparator.cc:157] Difference at 1288: 0.0441818, expected 0.686122\n",
      "E0000 00:00:1748694707.327890    3237 buffer_comparator.cc:157] Difference at 1289: 0.0444203, expected 0.69392\n",
      "2025-05-31 14:31:47.327894: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694707.329328    3237 buffer_comparator.cc:157] Difference at 1280: 0.0445944, expected 0.685772\n",
      "E0000 00:00:1748694707.329356    3237 buffer_comparator.cc:157] Difference at 1281: 0.0371115, expected 0.695207\n",
      "E0000 00:00:1748694707.329364    3237 buffer_comparator.cc:157] Difference at 1282: 0.0349444, expected 0.70036\n",
      "E0000 00:00:1748694707.329367    3237 buffer_comparator.cc:157] Difference at 1283: 0.0367766, expected 0.608521\n",
      "E0000 00:00:1748694707.329369    3237 buffer_comparator.cc:157] Difference at 1284: 0.0346433, expected 0.694442\n",
      "E0000 00:00:1748694707.329372    3237 buffer_comparator.cc:157] Difference at 1285: 0.0464954, expected 0.645032\n",
      "E0000 00:00:1748694707.329374    3237 buffer_comparator.cc:157] Difference at 1286: 0.0464664, expected 0.614836\n",
      "E0000 00:00:1748694707.329376    3237 buffer_comparator.cc:157] Difference at 1287: 0.0323101, expected 0.686831\n",
      "E0000 00:00:1748694707.329378    3237 buffer_comparator.cc:157] Difference at 1288: 0.0441818, expected 0.686122\n",
      "E0000 00:00:1748694707.329380    3237 buffer_comparator.cc:157] Difference at 1289: 0.0444203, expected 0.69392\n",
      "2025-05-31 14:31:47.329385: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m348/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5588 - sparse_categorical_accuracy: 0.2434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 14:31:49.367071: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_107', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-05-31 14:31:49.480107: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_107', 420 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "E0000 00:00:1748694709.661550    3239 buffer_comparator.cc:157] Difference at 160: 0.152941, expected 0.498814\n",
      "E0000 00:00:1748694709.661611    3239 buffer_comparator.cc:157] Difference at 161: 0.0784314, expected 0.448453\n",
      "E0000 00:00:1748694709.661620    3239 buffer_comparator.cc:157] Difference at 162: 0.101961, expected 0.461146\n",
      "E0000 00:00:1748694709.661623    3239 buffer_comparator.cc:157] Difference at 163: 0.141176, expected 0.614324\n",
      "E0000 00:00:1748694709.661626    3239 buffer_comparator.cc:157] Difference at 164: 0.0823529, expected 0.463469\n",
      "E0000 00:00:1748694709.661628    3239 buffer_comparator.cc:157] Difference at 165: 0.0980392, expected 0.475515\n",
      "E0000 00:00:1748694709.661630    3239 buffer_comparator.cc:157] Difference at 166: 0.145098, expected 0.545641\n",
      "E0000 00:00:1748694709.661632    3239 buffer_comparator.cc:157] Difference at 167: 0.101961, expected 0.442172\n",
      "E0000 00:00:1748694709.661635    3239 buffer_comparator.cc:157] Difference at 168: 0.117647, expected 0.521518\n",
      "E0000 00:00:1748694709.661637    3239 buffer_comparator.cc:157] Difference at 169: 0.164706, expected 0.477269\n",
      "2025-05-31 14:31:49.661645: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.664163    3239 buffer_comparator.cc:157] Difference at 160: 0.152941, expected 0.498814\n",
      "E0000 00:00:1748694709.664207    3239 buffer_comparator.cc:157] Difference at 161: 0.0784314, expected 0.448453\n",
      "E0000 00:00:1748694709.664217    3239 buffer_comparator.cc:157] Difference at 162: 0.101961, expected 0.461146\n",
      "E0000 00:00:1748694709.664221    3239 buffer_comparator.cc:157] Difference at 163: 0.141176, expected 0.614324\n",
      "E0000 00:00:1748694709.664225    3239 buffer_comparator.cc:157] Difference at 164: 0.0823529, expected 0.463469\n",
      "E0000 00:00:1748694709.664228    3239 buffer_comparator.cc:157] Difference at 165: 0.0980392, expected 0.475515\n",
      "E0000 00:00:1748694709.664231    3239 buffer_comparator.cc:157] Difference at 166: 0.145098, expected 0.545641\n",
      "E0000 00:00:1748694709.664235    3239 buffer_comparator.cc:157] Difference at 167: 0.101961, expected 0.442172\n",
      "E0000 00:00:1748694709.664238    3239 buffer_comparator.cc:157] Difference at 168: 0.117647, expected 0.521518\n",
      "E0000 00:00:1748694709.664242    3239 buffer_comparator.cc:157] Difference at 169: 0.164706, expected 0.477269\n",
      "2025-05-31 14:31:49.664249: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.666316    3239 buffer_comparator.cc:157] Difference at 320: 0.807843, expected 0.29897\n",
      "E0000 00:00:1748694709.666359    3239 buffer_comparator.cc:157] Difference at 321: 0.854902, expected 0.275208\n",
      "E0000 00:00:1748694709.666368    3239 buffer_comparator.cc:157] Difference at 322: 1, expected 0.25767\n",
      "E0000 00:00:1748694709.666370    3239 buffer_comparator.cc:157] Difference at 323: 0.792157, expected 0.346927\n",
      "E0000 00:00:1748694709.666373    3239 buffer_comparator.cc:157] Difference at 324: 0.835294, expected 0.260287\n",
      "E0000 00:00:1748694709.666375    3239 buffer_comparator.cc:157] Difference at 325: 0.996078, expected 0.283677\n",
      "E0000 00:00:1748694709.666377    3239 buffer_comparator.cc:157] Difference at 326: 0.8, expected 0.315654\n",
      "E0000 00:00:1748694709.666380    3239 buffer_comparator.cc:157] Difference at 327: 0.847059, expected 0.255002\n",
      "E0000 00:00:1748694709.666382    3239 buffer_comparator.cc:157] Difference at 328: 0.992157, expected 0.307315\n",
      "E0000 00:00:1748694709.666384    3239 buffer_comparator.cc:157] Difference at 329: 0.67451, expected 0.279405\n",
      "2025-05-31 14:31:49.666388: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.667808    3239 buffer_comparator.cc:157] Difference at 320: 0.807843, expected 0.29897\n",
      "E0000 00:00:1748694709.667849    3239 buffer_comparator.cc:157] Difference at 321: 0.854902, expected 0.275208\n",
      "E0000 00:00:1748694709.667857    3239 buffer_comparator.cc:157] Difference at 322: 1, expected 0.25767\n",
      "E0000 00:00:1748694709.667860    3239 buffer_comparator.cc:157] Difference at 323: 0.792157, expected 0.346927\n",
      "E0000 00:00:1748694709.667862    3239 buffer_comparator.cc:157] Difference at 324: 0.835294, expected 0.260287\n",
      "E0000 00:00:1748694709.667865    3239 buffer_comparator.cc:157] Difference at 325: 0.996078, expected 0.283677\n",
      "E0000 00:00:1748694709.667867    3239 buffer_comparator.cc:157] Difference at 326: 0.8, expected 0.315654\n",
      "E0000 00:00:1748694709.667869    3239 buffer_comparator.cc:157] Difference at 327: 0.847059, expected 0.255002\n",
      "E0000 00:00:1748694709.667871    3239 buffer_comparator.cc:157] Difference at 328: 0.992157, expected 0.307315\n",
      "E0000 00:00:1748694709.667873    3239 buffer_comparator.cc:157] Difference at 329: 0.67451, expected 0.279405\n",
      "2025-05-31 14:31:49.667878: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.669371    3239 buffer_comparator.cc:157] Difference at 641: 0.101961, expected 0.23961\n",
      "E0000 00:00:1748694709.669413    3239 buffer_comparator.cc:157] Difference at 642: 0.105882, expected 0.237859\n",
      "E0000 00:00:1748694709.669422    3239 buffer_comparator.cc:157] Difference at 643: 0.12549, expected 0.295283\n",
      "E0000 00:00:1748694709.669425    3239 buffer_comparator.cc:157] Difference at 644: 0.0941176, expected 0.227808\n",
      "E0000 00:00:1748694709.669427    3239 buffer_comparator.cc:157] Difference at 645: 0.0980392, expected 0.241782\n",
      "E0000 00:00:1748694709.669429    3239 buffer_comparator.cc:157] Difference at 646: 0.117647, expected 0.285626\n",
      "E0000 00:00:1748694709.669432    3239 buffer_comparator.cc:157] Difference at 648: 0.0980392, expected 0.239876\n",
      "E0000 00:00:1748694709.669434    3239 buffer_comparator.cc:157] Difference at 650: 0.0901961, expected 0.494769\n",
      "E0000 00:00:1748694709.669436    3239 buffer_comparator.cc:157] Difference at 651: 0.0941176, expected 0.440825\n",
      "E0000 00:00:1748694709.669438    3239 buffer_comparator.cc:157] Difference at 652: 0.113725, expected 0.456501\n",
      "2025-05-31 14:31:49.669443: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.670884    3239 buffer_comparator.cc:157] Difference at 641: 0.101961, expected 0.23961\n",
      "E0000 00:00:1748694709.670926    3239 buffer_comparator.cc:157] Difference at 642: 0.105882, expected 0.237859\n",
      "E0000 00:00:1748694709.670934    3239 buffer_comparator.cc:157] Difference at 643: 0.12549, expected 0.295283\n",
      "E0000 00:00:1748694709.670937    3239 buffer_comparator.cc:157] Difference at 644: 0.0941176, expected 0.227808\n",
      "E0000 00:00:1748694709.670939    3239 buffer_comparator.cc:157] Difference at 645: 0.0980392, expected 0.241782\n",
      "E0000 00:00:1748694709.670941    3239 buffer_comparator.cc:157] Difference at 646: 0.117647, expected 0.285626\n",
      "E0000 00:00:1748694709.670943    3239 buffer_comparator.cc:157] Difference at 648: 0.0980392, expected 0.239876\n",
      "E0000 00:00:1748694709.670945    3239 buffer_comparator.cc:157] Difference at 650: 0.0901961, expected 0.494769\n",
      "E0000 00:00:1748694709.670948    3239 buffer_comparator.cc:157] Difference at 651: 0.0941176, expected 0.440825\n",
      "E0000 00:00:1748694709.670950    3239 buffer_comparator.cc:157] Difference at 652: 0.113725, expected 0.456501\n",
      "2025-05-31 14:31:49.670954: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.672364    3239 buffer_comparator.cc:157] Difference at 641: 0.101961, expected 0.23961\n",
      "E0000 00:00:1748694709.672405    3239 buffer_comparator.cc:157] Difference at 642: 0.105882, expected 0.237859\n",
      "E0000 00:00:1748694709.672414    3239 buffer_comparator.cc:157] Difference at 643: 0.12549, expected 0.295283\n",
      "E0000 00:00:1748694709.672416    3239 buffer_comparator.cc:157] Difference at 644: 0.0941176, expected 0.227808\n",
      "E0000 00:00:1748694709.672420    3239 buffer_comparator.cc:157] Difference at 645: 0.0980392, expected 0.241782\n",
      "E0000 00:00:1748694709.672422    3239 buffer_comparator.cc:157] Difference at 646: 0.117647, expected 0.285626\n",
      "E0000 00:00:1748694709.672424    3239 buffer_comparator.cc:157] Difference at 648: 0.0980392, expected 0.239876\n",
      "E0000 00:00:1748694709.672426    3239 buffer_comparator.cc:157] Difference at 650: 0.0901961, expected 0.494769\n",
      "E0000 00:00:1748694709.672428    3239 buffer_comparator.cc:157] Difference at 651: 0.0941176, expected 0.440825\n",
      "E0000 00:00:1748694709.672430    3239 buffer_comparator.cc:157] Difference at 652: 0.113725, expected 0.456501\n",
      "2025-05-31 14:31:49.672435: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.673908    3239 buffer_comparator.cc:157] Difference at 641: 0.101961, expected 0.23961\n",
      "E0000 00:00:1748694709.673948    3239 buffer_comparator.cc:157] Difference at 642: 0.105882, expected 0.237859\n",
      "E0000 00:00:1748694709.673957    3239 buffer_comparator.cc:157] Difference at 643: 0.12549, expected 0.295283\n",
      "E0000 00:00:1748694709.673960    3239 buffer_comparator.cc:157] Difference at 644: 0.0941176, expected 0.227808\n",
      "E0000 00:00:1748694709.673962    3239 buffer_comparator.cc:157] Difference at 645: 0.0980392, expected 0.241782\n",
      "E0000 00:00:1748694709.673964    3239 buffer_comparator.cc:157] Difference at 646: 0.117647, expected 0.285626\n",
      "E0000 00:00:1748694709.673966    3239 buffer_comparator.cc:157] Difference at 648: 0.0980392, expected 0.239876\n",
      "E0000 00:00:1748694709.673968    3239 buffer_comparator.cc:157] Difference at 650: 0.0901961, expected 0.494769\n",
      "E0000 00:00:1748694709.673971    3239 buffer_comparator.cc:157] Difference at 651: 0.0941176, expected 0.440825\n",
      "E0000 00:00:1748694709.673973    3239 buffer_comparator.cc:157] Difference at 652: 0.113725, expected 0.456501\n",
      "2025-05-31 14:31:49.673977: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.676443    3239 buffer_comparator.cc:157] Difference at 641: 0.101961, expected 0.23961\n",
      "E0000 00:00:1748694709.676490    3239 buffer_comparator.cc:157] Difference at 642: 0.105882, expected 0.237859\n",
      "E0000 00:00:1748694709.676500    3239 buffer_comparator.cc:157] Difference at 643: 0.12549, expected 0.295283\n",
      "E0000 00:00:1748694709.676504    3239 buffer_comparator.cc:157] Difference at 644: 0.0941176, expected 0.227808\n",
      "E0000 00:00:1748694709.676508    3239 buffer_comparator.cc:157] Difference at 645: 0.0980392, expected 0.241782\n",
      "E0000 00:00:1748694709.676512    3239 buffer_comparator.cc:157] Difference at 646: 0.117647, expected 0.285626\n",
      "E0000 00:00:1748694709.676515    3239 buffer_comparator.cc:157] Difference at 648: 0.0980392, expected 0.239876\n",
      "E0000 00:00:1748694709.676518    3239 buffer_comparator.cc:157] Difference at 650: 0.0901961, expected 0.494769\n",
      "E0000 00:00:1748694709.676522    3239 buffer_comparator.cc:157] Difference at 651: 0.0941176, expected 0.440825\n",
      "E0000 00:00:1748694709.676525    3239 buffer_comparator.cc:157] Difference at 652: 0.113725, expected 0.456501\n",
      "2025-05-31 14:31:49.676532: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.678375    3239 buffer_comparator.cc:157] Difference at 1280: 0.517647, expected 0.320752\n",
      "E0000 00:00:1748694709.678418    3239 buffer_comparator.cc:157] Difference at 1281: 0.596078, expected 0.290573\n",
      "E0000 00:00:1748694709.678428    3239 buffer_comparator.cc:157] Difference at 1282: 0.682353, expected 0.281127\n",
      "E0000 00:00:1748694709.678433    3239 buffer_comparator.cc:157] Difference at 1284: 0.588235, expected 0.285561\n",
      "E0000 00:00:1748694709.678436    3239 buffer_comparator.cc:157] Difference at 1285: 0.67451, expected 0.27679\n",
      "E0000 00:00:1748694709.678440    3239 buffer_comparator.cc:157] Difference at 1286: 0.513726, expected 0.35545\n",
      "E0000 00:00:1748694709.678443    3239 buffer_comparator.cc:157] Difference at 1287: 0.588235, expected 0.286592\n",
      "E0000 00:00:1748694709.678447    3239 buffer_comparator.cc:157] Difference at 1288: 0.67451, expected 0.336764\n",
      "E0000 00:00:1748694709.678450    3239 buffer_comparator.cc:157] Difference at 1289: 0.52549, expected 0.296341\n",
      "E0000 00:00:1748694709.678454    3239 buffer_comparator.cc:157] Difference at 1290: 0.6, expected 0.294348\n",
      "2025-05-31 14:31:49.678460: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.680204    3239 buffer_comparator.cc:157] Difference at 1280: 0.517647, expected 0.320752\n",
      "E0000 00:00:1748694709.680246    3239 buffer_comparator.cc:157] Difference at 1281: 0.596078, expected 0.290573\n",
      "E0000 00:00:1748694709.680258    3239 buffer_comparator.cc:157] Difference at 1282: 0.682353, expected 0.281127\n",
      "E0000 00:00:1748694709.680263    3239 buffer_comparator.cc:157] Difference at 1284: 0.588235, expected 0.285561\n",
      "E0000 00:00:1748694709.680291    3239 buffer_comparator.cc:157] Difference at 1285: 0.67451, expected 0.27679\n",
      "E0000 00:00:1748694709.680295    3239 buffer_comparator.cc:157] Difference at 1286: 0.513726, expected 0.35545\n",
      "E0000 00:00:1748694709.680298    3239 buffer_comparator.cc:157] Difference at 1287: 0.588235, expected 0.286592\n",
      "E0000 00:00:1748694709.680300    3239 buffer_comparator.cc:157] Difference at 1288: 0.67451, expected 0.336764\n",
      "E0000 00:00:1748694709.680302    3239 buffer_comparator.cc:157] Difference at 1289: 0.52549, expected 0.296341\n",
      "E0000 00:00:1748694709.680304    3239 buffer_comparator.cc:157] Difference at 1290: 0.6, expected 0.294348\n",
      "2025-05-31 14:31:49.680310: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.681828    3239 buffer_comparator.cc:157] Difference at 1280: 0.517647, expected 0.320752\n",
      "E0000 00:00:1748694709.681870    3239 buffer_comparator.cc:157] Difference at 1281: 0.596078, expected 0.290573\n",
      "E0000 00:00:1748694709.681881    3239 buffer_comparator.cc:157] Difference at 1282: 0.682353, expected 0.281127\n",
      "E0000 00:00:1748694709.681885    3239 buffer_comparator.cc:157] Difference at 1284: 0.588235, expected 0.285561\n",
      "E0000 00:00:1748694709.681887    3239 buffer_comparator.cc:157] Difference at 1285: 0.67451, expected 0.27679\n",
      "E0000 00:00:1748694709.681890    3239 buffer_comparator.cc:157] Difference at 1286: 0.513726, expected 0.35545\n",
      "E0000 00:00:1748694709.681892    3239 buffer_comparator.cc:157] Difference at 1287: 0.588235, expected 0.286592\n",
      "E0000 00:00:1748694709.681894    3239 buffer_comparator.cc:157] Difference at 1288: 0.67451, expected 0.336764\n",
      "E0000 00:00:1748694709.681896    3239 buffer_comparator.cc:157] Difference at 1289: 0.52549, expected 0.296341\n",
      "E0000 00:00:1748694709.681898    3239 buffer_comparator.cc:157] Difference at 1290: 0.6, expected 0.294348\n",
      "2025-05-31 14:31:49.681903: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.683543    3239 buffer_comparator.cc:157] Difference at 0: 1.18071, expected 0.663259\n",
      "E0000 00:00:1748694709.683584    3239 buffer_comparator.cc:157] Difference at 1: 1.03668, expected 0.586929\n",
      "E0000 00:00:1748694709.683594    3239 buffer_comparator.cc:157] Difference at 2: 1.08101, expected 0.597651\n",
      "E0000 00:00:1748694709.683597    3239 buffer_comparator.cc:157] Difference at 3: 1.37352, expected 0.769395\n",
      "E0000 00:00:1748694709.683599    3239 buffer_comparator.cc:157] Difference at 4: 1.106, expected 0.612408\n",
      "E0000 00:00:1748694709.683601    3239 buffer_comparator.cc:157] Difference at 5: 1.1384, expected 0.636494\n",
      "E0000 00:00:1748694709.683603    3239 buffer_comparator.cc:157] Difference at 6: 1.25477, expected 0.713305\n",
      "E0000 00:00:1748694709.683606    3239 buffer_comparator.cc:157] Difference at 7: 1.09447, expected 0.588957\n",
      "E0000 00:00:1748694709.683608    3239 buffer_comparator.cc:157] Difference at 8: 1.27734, expected 0.695131\n",
      "E0000 00:00:1748694709.683610    3239 buffer_comparator.cc:157] Difference at 9: 1.06581, expected 0.616911\n",
      "2025-05-31 14:31:49.683615: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.685095    3239 buffer_comparator.cc:157] Difference at 1280: 1.21569, expected 0.320752\n",
      "E0000 00:00:1748694709.685135    3239 buffer_comparator.cc:157] Difference at 1281: 1.17255, expected 0.290573\n",
      "E0000 00:00:1748694709.685144    3239 buffer_comparator.cc:157] Difference at 1282: 1.14902, expected 0.281127\n",
      "E0000 00:00:1748694709.685146    3239 buffer_comparator.cc:157] Difference at 1283: 1.17255, expected 0.369417\n",
      "E0000 00:00:1748694709.685148    3239 buffer_comparator.cc:157] Difference at 1284: 1.14902, expected 0.285561\n",
      "E0000 00:00:1748694709.685150    3239 buffer_comparator.cc:157] Difference at 1285: 1.13725, expected 0.27679\n",
      "E0000 00:00:1748694709.685153    3239 buffer_comparator.cc:157] Difference at 1286: 1.13725, expected 0.35545\n",
      "E0000 00:00:1748694709.685155    3239 buffer_comparator.cc:157] Difference at 1287: 1.15294, expected 0.286592\n",
      "E0000 00:00:1748694709.685157    3239 buffer_comparator.cc:157] Difference at 1288: 1.11765, expected 0.336764\n",
      "E0000 00:00:1748694709.685159    3239 buffer_comparator.cc:157] Difference at 1289: 1.1451, expected 0.296341\n",
      "2025-05-31 14:31:49.685163: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.686640    3239 buffer_comparator.cc:157] Difference at 2560: 1.1451, expected 0.574451\n",
      "E0000 00:00:1748694709.686685    3239 buffer_comparator.cc:157] Difference at 2561: 1.19608, expected 0.493238\n",
      "E0000 00:00:1748694709.686693    3239 buffer_comparator.cc:157] Difference at 2562: 1.43922, expected 0.507937\n",
      "E0000 00:00:1748694709.686696    3239 buffer_comparator.cc:157] Difference at 2563: 1.25098, expected 0.664823\n",
      "E0000 00:00:1748694709.686698    3239 buffer_comparator.cc:157] Difference at 2564: 1.33726, expected 0.512715\n",
      "E0000 00:00:1748694709.686700    3239 buffer_comparator.cc:157] Difference at 2565: 0.882353, expected 0.547045\n",
      "E0000 00:00:1748694709.686702    3239 buffer_comparator.cc:157] Difference at 2566: 0.815686, expected 0.606695\n",
      "E0000 00:00:1748694709.686704    3239 buffer_comparator.cc:157] Difference at 2567: 0.894118, expected 0.489361\n",
      "E0000 00:00:1748694709.686706    3239 buffer_comparator.cc:157] Difference at 2568: 0.811765, expected 0.598747\n",
      "E0000 00:00:1748694709.686709    3239 buffer_comparator.cc:157] Difference at 2570: 0.741176, expected 0.413696\n",
      "2025-05-31 14:31:49.686713: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.688938    3239 buffer_comparator.cc:157] Difference at 2560: 1.1451, expected 0.574451\n",
      "E0000 00:00:1748694709.688977    3239 buffer_comparator.cc:157] Difference at 2561: 1.19608, expected 0.493238\n",
      "E0000 00:00:1748694709.688986    3239 buffer_comparator.cc:157] Difference at 2562: 1.43922, expected 0.507937\n",
      "E0000 00:00:1748694709.688989    3239 buffer_comparator.cc:157] Difference at 2563: 1.25098, expected 0.664823\n",
      "E0000 00:00:1748694709.688992    3239 buffer_comparator.cc:157] Difference at 2564: 1.33726, expected 0.512715\n",
      "E0000 00:00:1748694709.688994    3239 buffer_comparator.cc:157] Difference at 2565: 0.882353, expected 0.547045\n",
      "E0000 00:00:1748694709.688996    3239 buffer_comparator.cc:157] Difference at 2566: 0.815686, expected 0.606695\n",
      "E0000 00:00:1748694709.688998    3239 buffer_comparator.cc:157] Difference at 2567: 0.894118, expected 0.489361\n",
      "E0000 00:00:1748694709.689000    3239 buffer_comparator.cc:157] Difference at 2568: 0.811765, expected 0.598747\n",
      "E0000 00:00:1748694709.689002    3239 buffer_comparator.cc:157] Difference at 2570: 0.741176, expected 0.413696\n",
      "2025-05-31 14:31:49.689007: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.690812    3239 buffer_comparator.cc:157] Difference at 4: 462.521, expected 524.645\n",
      "E0000 00:00:1748694709.690846    3239 buffer_comparator.cc:157] Difference at 9: 460.304, expected 533.142\n",
      "E0000 00:00:1748694709.690855    3239 buffer_comparator.cc:157] Difference at 24: 470.756, expected 525.576\n",
      "E0000 00:00:1748694709.690858    3239 buffer_comparator.cc:157] Difference at 29: 467.315, expected 542.301\n",
      "E0000 00:00:1748694709.690861    3239 buffer_comparator.cc:157] Difference at 31: 475.143, expected 529.745\n",
      "E0000 00:00:1748694709.690863    3239 buffer_comparator.cc:157] Difference at 39: 452.327, expected 533.352\n",
      "E0000 00:00:1748694709.690865    3239 buffer_comparator.cc:157] Difference at 49: 468.902, expected 540.13\n",
      "E0000 00:00:1748694709.690867    3239 buffer_comparator.cc:157] Difference at 59: 478.872, expected 537.441\n",
      "E0000 00:00:1748694709.690870    3239 buffer_comparator.cc:157] Difference at 79: 459.9, expected 543.004\n",
      "E0000 00:00:1748694709.690872    3239 buffer_comparator.cc:157] Difference at 84: 464.779, expected 521.55\n",
      "2025-05-31 14:31:49.690877: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.692255    3239 buffer_comparator.cc:157] Difference at 4: 444.62, expected 524.645\n",
      "E0000 00:00:1748694709.692290    3239 buffer_comparator.cc:157] Difference at 8: 458.384, expected 519.724\n",
      "E0000 00:00:1748694709.692298    3239 buffer_comparator.cc:157] Difference at 9: 477.482, expected 533.142\n",
      "E0000 00:00:1748694709.692301    3239 buffer_comparator.cc:157] Difference at 14: 437.749, expected 513.793\n",
      "E0000 00:00:1748694709.692303    3239 buffer_comparator.cc:157] Difference at 18: 467.451, expected 521.412\n",
      "E0000 00:00:1748694709.692306    3239 buffer_comparator.cc:157] Difference at 24: 435.018, expected 525.576\n",
      "E0000 00:00:1748694709.692308    3239 buffer_comparator.cc:157] Difference at 29: 477.662, expected 542.301\n",
      "E0000 00:00:1748694709.692310    3239 buffer_comparator.cc:157] Difference at 34: 443.62, expected 524.689\n",
      "E0000 00:00:1748694709.692312    3239 buffer_comparator.cc:157] Difference at 39: 462.863, expected 533.352\n",
      "E0000 00:00:1748694709.692315    3239 buffer_comparator.cc:157] Difference at 44: 449.614, expected 525.942\n",
      "2025-05-31 14:31:49.692320: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.693572    3239 buffer_comparator.cc:157] Difference at 160: 8.7764, expected 511.021\n",
      "E0000 00:00:1748694709.693609    3239 buffer_comparator.cc:157] Difference at 161: 7.15753, expected 528.865\n",
      "E0000 00:00:1748694709.693618    3239 buffer_comparator.cc:157] Difference at 162: 8.5784, expected 513.821\n",
      "E0000 00:00:1748694709.693621    3239 buffer_comparator.cc:157] Difference at 163: 7.73242, expected 529.153\n",
      "E0000 00:00:1748694709.693623    3239 buffer_comparator.cc:157] Difference at 164: 7.60182, expected 524.363\n",
      "E0000 00:00:1748694709.693625    3239 buffer_comparator.cc:157] Difference at 165: 6.87709, expected 520.622\n",
      "E0000 00:00:1748694709.693627    3239 buffer_comparator.cc:157] Difference at 166: 6.96822, expected 524.213\n",
      "E0000 00:00:1748694709.693629    3239 buffer_comparator.cc:157] Difference at 167: 9.0161, expected 520.065\n",
      "E0000 00:00:1748694709.693632    3239 buffer_comparator.cc:157] Difference at 168: 7.05743, expected 520.372\n",
      "E0000 00:00:1748694709.693634    3239 buffer_comparator.cc:157] Difference at 169: 7.2982, expected 539.908\n",
      "2025-05-31 14:31:49.693639: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.695149    3239 buffer_comparator.cc:157] Difference at 160: 8.7764, expected 511.021\n",
      "E0000 00:00:1748694709.695187    3239 buffer_comparator.cc:157] Difference at 161: 7.15753, expected 528.865\n",
      "E0000 00:00:1748694709.695196    3239 buffer_comparator.cc:157] Difference at 162: 8.5784, expected 513.821\n",
      "E0000 00:00:1748694709.695198    3239 buffer_comparator.cc:157] Difference at 163: 7.73242, expected 529.153\n",
      "E0000 00:00:1748694709.695201    3239 buffer_comparator.cc:157] Difference at 164: 7.60182, expected 524.363\n",
      "E0000 00:00:1748694709.695203    3239 buffer_comparator.cc:157] Difference at 165: 6.87709, expected 520.622\n",
      "E0000 00:00:1748694709.695205    3239 buffer_comparator.cc:157] Difference at 166: 6.96822, expected 524.213\n",
      "E0000 00:00:1748694709.695207    3239 buffer_comparator.cc:157] Difference at 167: 9.0161, expected 520.065\n",
      "E0000 00:00:1748694709.695209    3239 buffer_comparator.cc:157] Difference at 168: 7.05743, expected 520.372\n",
      "E0000 00:00:1748694709.695212    3239 buffer_comparator.cc:157] Difference at 169: 7.2982, expected 539.908\n",
      "2025-05-31 14:31:49.695216: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.696627    3239 buffer_comparator.cc:157] Difference at 160: 8.7764, expected 511.021\n",
      "E0000 00:00:1748694709.696661    3239 buffer_comparator.cc:157] Difference at 161: 7.15753, expected 528.865\n",
      "E0000 00:00:1748694709.696669    3239 buffer_comparator.cc:157] Difference at 162: 8.5784, expected 513.821\n",
      "E0000 00:00:1748694709.696672    3239 buffer_comparator.cc:157] Difference at 163: 7.73242, expected 529.153\n",
      "E0000 00:00:1748694709.696674    3239 buffer_comparator.cc:157] Difference at 164: 7.60182, expected 524.363\n",
      "E0000 00:00:1748694709.696676    3239 buffer_comparator.cc:157] Difference at 165: 6.87709, expected 520.622\n",
      "E0000 00:00:1748694709.696678    3239 buffer_comparator.cc:157] Difference at 166: 6.96822, expected 524.213\n",
      "E0000 00:00:1748694709.696680    3239 buffer_comparator.cc:157] Difference at 167: 9.0161, expected 520.065\n",
      "E0000 00:00:1748694709.696683    3239 buffer_comparator.cc:157] Difference at 168: 7.05743, expected 520.372\n",
      "E0000 00:00:1748694709.696685    3239 buffer_comparator.cc:157] Difference at 169: 7.2982, expected 539.908\n",
      "2025-05-31 14:31:49.696689: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.697962    3239 buffer_comparator.cc:157] Difference at 320: 9.00775, expected 514.098\n",
      "E0000 00:00:1748694709.697996    3239 buffer_comparator.cc:157] Difference at 321: 7.34443, expected 533.691\n",
      "E0000 00:00:1748694709.698005    3239 buffer_comparator.cc:157] Difference at 322: 8.78197, expected 514.105\n",
      "E0000 00:00:1748694709.698013    3239 buffer_comparator.cc:157] Difference at 323: 7.88998, expected 529.242\n",
      "E0000 00:00:1748694709.698015    3239 buffer_comparator.cc:157] Difference at 324: 7.89493, expected 522.997\n",
      "E0000 00:00:1748694709.698017    3239 buffer_comparator.cc:157] Difference at 325: 7.11637, expected 512.755\n",
      "E0000 00:00:1748694709.698019    3239 buffer_comparator.cc:157] Difference at 326: 7.27832, expected 526.9\n",
      "E0000 00:00:1748694709.698022    3239 buffer_comparator.cc:157] Difference at 327: 9.33826, expected 518.053\n",
      "E0000 00:00:1748694709.698024    3239 buffer_comparator.cc:157] Difference at 328: 7.33134, expected 529.293\n",
      "E0000 00:00:1748694709.698026    3239 buffer_comparator.cc:157] Difference at 329: 7.68061, expected 536.124\n",
      "2025-05-31 14:31:49.698031: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.699607    3239 buffer_comparator.cc:157] Difference at 79: 479.1, expected 543.004\n",
      "E0000 00:00:1748694709.699649    3239 buffer_comparator.cc:157] Difference at 89: 467.887, expected 528.819\n",
      "E0000 00:00:1748694709.699661    3239 buffer_comparator.cc:157] Difference at 129: 482.837, expected 538.154\n",
      "E0000 00:00:1748694709.699666    3239 buffer_comparator.cc:157] Difference at 139: 489.13, expected 545.178\n",
      "E0000 00:00:1748694709.699670    3239 buffer_comparator.cc:157] Difference at 189: 475.694, expected 528.776\n",
      "E0000 00:00:1748694709.699675    3239 buffer_comparator.cc:157] Difference at 219: 469.395, expected 532.3\n",
      "E0000 00:00:1748694709.699679    3239 buffer_comparator.cc:157] Difference at 269: 474.823, expected 535.096\n",
      "E0000 00:00:1748694709.699683    3239 buffer_comparator.cc:157] Difference at 299: 480.417, expected 536.448\n",
      "E0000 00:00:1748694709.699687    3239 buffer_comparator.cc:157] Difference at 320: 2.35653, expected 514.098\n",
      "E0000 00:00:1748694709.699691    3239 buffer_comparator.cc:157] Difference at 321: 1.9374, expected 533.691\n",
      "2025-05-31 14:31:49.699699: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.702245    3239 buffer_comparator.cc:157] Difference at 320: 2.35653, expected 514.098\n",
      "E0000 00:00:1748694709.702281    3239 buffer_comparator.cc:157] Difference at 321: 1.9374, expected 533.691\n",
      "E0000 00:00:1748694709.702289    3239 buffer_comparator.cc:157] Difference at 322: 2.31087, expected 514.105\n",
      "E0000 00:00:1748694709.702292    3239 buffer_comparator.cc:157] Difference at 323: 2.06736, expected 529.242\n",
      "E0000 00:00:1748694709.702294    3239 buffer_comparator.cc:157] Difference at 324: 2.00466, expected 522.997\n",
      "E0000 00:00:1748694709.702296    3239 buffer_comparator.cc:157] Difference at 325: 1.8063, expected 512.755\n",
      "E0000 00:00:1748694709.702299    3239 buffer_comparator.cc:157] Difference at 326: 1.84534, expected 526.9\n",
      "E0000 00:00:1748694709.702301    3239 buffer_comparator.cc:157] Difference at 327: 2.34693, expected 518.053\n",
      "E0000 00:00:1748694709.702303    3239 buffer_comparator.cc:157] Difference at 328: 1.85736, expected 529.293\n",
      "E0000 00:00:1748694709.702305    3239 buffer_comparator.cc:157] Difference at 329: 1.94035, expected 536.124\n",
      "2025-05-31 14:31:49.702310: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.703997    3239 buffer_comparator.cc:157] Difference at 640: 2.63926, expected 519.471\n",
      "E0000 00:00:1748694709.704037    3239 buffer_comparator.cc:157] Difference at 641: 2.15364, expected 536.334\n",
      "E0000 00:00:1748694709.704045    3239 buffer_comparator.cc:157] Difference at 642: 2.52913, expected 516.292\n",
      "E0000 00:00:1748694709.704048    3239 buffer_comparator.cc:157] Difference at 643: 2.30848, expected 534.739\n",
      "E0000 00:00:1748694709.704050    3239 buffer_comparator.cc:157] Difference at 644: 1.87455, expected 524.862\n",
      "E0000 00:00:1748694709.704053    3239 buffer_comparator.cc:157] Difference at 645: 1.70698, expected 524.425\n",
      "E0000 00:00:1748694709.704055    3239 buffer_comparator.cc:157] Difference at 646: 1.73996, expected 528.735\n",
      "E0000 00:00:1748694709.704057    3239 buffer_comparator.cc:157] Difference at 647: 2.21005, expected 522.209\n",
      "E0000 00:00:1748694709.704059    3239 buffer_comparator.cc:157] Difference at 648: 1.7149, expected 525.539\n",
      "E0000 00:00:1748694709.704061    3239 buffer_comparator.cc:157] Difference at 649: 1.82534, expected 540.606\n",
      "2025-05-31 14:31:49.704066: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.705597    3239 buffer_comparator.cc:157] Difference at 4: 444.62, expected 524.645\n",
      "E0000 00:00:1748694709.705632    3239 buffer_comparator.cc:157] Difference at 8: 458.384, expected 519.724\n",
      "E0000 00:00:1748694709.705640    3239 buffer_comparator.cc:157] Difference at 9: 477.482, expected 533.142\n",
      "E0000 00:00:1748694709.705643    3239 buffer_comparator.cc:157] Difference at 14: 437.749, expected 513.793\n",
      "E0000 00:00:1748694709.705645    3239 buffer_comparator.cc:157] Difference at 18: 467.451, expected 521.412\n",
      "E0000 00:00:1748694709.705648    3239 buffer_comparator.cc:157] Difference at 24: 435.018, expected 525.576\n",
      "E0000 00:00:1748694709.705650    3239 buffer_comparator.cc:157] Difference at 29: 477.662, expected 542.301\n",
      "E0000 00:00:1748694709.705652    3239 buffer_comparator.cc:157] Difference at 34: 443.62, expected 524.689\n",
      "E0000 00:00:1748694709.705655    3239 buffer_comparator.cc:157] Difference at 39: 462.863, expected 533.352\n",
      "E0000 00:00:1748694709.705657    3239 buffer_comparator.cc:157] Difference at 44: 449.614, expected 525.942\n",
      "2025-05-31 14:31:49.705661: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.707133    3239 buffer_comparator.cc:157] Difference at 640: 10.2023, expected 519.471\n",
      "E0000 00:00:1748694709.707175    3239 buffer_comparator.cc:157] Difference at 641: 8.05916, expected 536.334\n",
      "E0000 00:00:1748694709.707183    3239 buffer_comparator.cc:157] Difference at 642: 9.38072, expected 516.292\n",
      "E0000 00:00:1748694709.707186    3239 buffer_comparator.cc:157] Difference at 643: 9.19283, expected 534.739\n",
      "E0000 00:00:1748694709.707188    3239 buffer_comparator.cc:157] Difference at 644: 8.13368, expected 524.862\n",
      "E0000 00:00:1748694709.707191    3239 buffer_comparator.cc:157] Difference at 645: 7.38761, expected 524.425\n",
      "E0000 00:00:1748694709.707193    3239 buffer_comparator.cc:157] Difference at 646: 8.12109, expected 528.735\n",
      "E0000 00:00:1748694709.707195    3239 buffer_comparator.cc:157] Difference at 647: 9.66667, expected 522.209\n",
      "E0000 00:00:1748694709.707197    3239 buffer_comparator.cc:157] Difference at 648: 7.74682, expected 525.539\n",
      "E0000 00:00:1748694709.707199    3239 buffer_comparator.cc:157] Difference at 649: 8.22537, expected 540.606\n",
      "2025-05-31 14:31:49.707204: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.708793    3239 buffer_comparator.cc:157] Difference at 640: 10.2023, expected 519.471\n",
      "E0000 00:00:1748694709.708828    3239 buffer_comparator.cc:157] Difference at 641: 8.05916, expected 536.334\n",
      "E0000 00:00:1748694709.708836    3239 buffer_comparator.cc:157] Difference at 642: 9.38072, expected 516.292\n",
      "E0000 00:00:1748694709.708839    3239 buffer_comparator.cc:157] Difference at 643: 9.19283, expected 534.739\n",
      "E0000 00:00:1748694709.708841    3239 buffer_comparator.cc:157] Difference at 644: 8.13368, expected 524.862\n",
      "E0000 00:00:1748694709.708843    3239 buffer_comparator.cc:157] Difference at 645: 7.38761, expected 524.425\n",
      "E0000 00:00:1748694709.708845    3239 buffer_comparator.cc:157] Difference at 646: 8.12109, expected 528.735\n",
      "E0000 00:00:1748694709.708847    3239 buffer_comparator.cc:157] Difference at 647: 9.66667, expected 522.209\n",
      "E0000 00:00:1748694709.708850    3239 buffer_comparator.cc:157] Difference at 648: 7.74682, expected 525.539\n",
      "E0000 00:00:1748694709.708852    3239 buffer_comparator.cc:157] Difference at 649: 8.22537, expected 540.606\n",
      "2025-05-31 14:31:49.708856: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.710280    3239 buffer_comparator.cc:157] Difference at 640: 10.2023, expected 519.471\n",
      "E0000 00:00:1748694709.710315    3239 buffer_comparator.cc:157] Difference at 641: 8.05916, expected 536.334\n",
      "E0000 00:00:1748694709.710324    3239 buffer_comparator.cc:157] Difference at 642: 9.38072, expected 516.292\n",
      "E0000 00:00:1748694709.710326    3239 buffer_comparator.cc:157] Difference at 643: 9.19283, expected 534.739\n",
      "E0000 00:00:1748694709.710329    3239 buffer_comparator.cc:157] Difference at 644: 8.13368, expected 524.862\n",
      "E0000 00:00:1748694709.710331    3239 buffer_comparator.cc:157] Difference at 645: 7.38761, expected 524.425\n",
      "E0000 00:00:1748694709.710333    3239 buffer_comparator.cc:157] Difference at 646: 8.12109, expected 528.735\n",
      "E0000 00:00:1748694709.710335    3239 buffer_comparator.cc:157] Difference at 647: 9.66667, expected 522.209\n",
      "E0000 00:00:1748694709.710337    3239 buffer_comparator.cc:157] Difference at 648: 7.74682, expected 525.539\n",
      "E0000 00:00:1748694709.710339    3239 buffer_comparator.cc:157] Difference at 649: 8.22537, expected 540.606\n",
      "2025-05-31 14:31:49.710344: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.717187    3239 buffer_comparator.cc:157] Difference at 79: 479.1, expected 543.004\n",
      "E0000 00:00:1748694709.717222    3239 buffer_comparator.cc:157] Difference at 89: 467.887, expected 528.819\n",
      "E0000 00:00:1748694709.717231    3239 buffer_comparator.cc:157] Difference at 129: 482.837, expected 538.154\n",
      "E0000 00:00:1748694709.717234    3239 buffer_comparator.cc:157] Difference at 139: 489.13, expected 545.178\n",
      "E0000 00:00:1748694709.717236    3239 buffer_comparator.cc:157] Difference at 189: 475.694, expected 528.776\n",
      "E0000 00:00:1748694709.717239    3239 buffer_comparator.cc:157] Difference at 219: 469.395, expected 532.3\n",
      "E0000 00:00:1748694709.717241    3239 buffer_comparator.cc:157] Difference at 269: 474.823, expected 535.096\n",
      "E0000 00:00:1748694709.717244    3239 buffer_comparator.cc:157] Difference at 299: 480.417, expected 536.448\n",
      "E0000 00:00:1748694709.717246    3239 buffer_comparator.cc:157] Difference at 372: 451.963, expected 507.788\n",
      "E0000 00:00:1748694709.717248    3239 buffer_comparator.cc:157] Difference at 379: 469.767, expected 532.494\n",
      "2025-05-31 14:31:49.717253: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.719349    3239 buffer_comparator.cc:157] Difference at 16: 0.854902, expected 0.0405081\n",
      "E0000 00:00:1748694709.719386    3239 buffer_comparator.cc:157] Difference at 17: 0.831373, expected 0.0446389\n",
      "E0000 00:00:1748694709.719394    3239 buffer_comparator.cc:157] Difference at 18: 0.854902, expected 0.0332528\n",
      "E0000 00:00:1748694709.719397    3239 buffer_comparator.cc:157] Difference at 19: 0.827451, expected 0.0329159\n",
      "E0000 00:00:1748694709.719399    3239 buffer_comparator.cc:157] Difference at 20: 0.823529, expected 0.0301345\n",
      "E0000 00:00:1748694709.719401    3239 buffer_comparator.cc:157] Difference at 21: 0.784314, expected 0.0431783\n",
      "E0000 00:00:1748694709.719403    3239 buffer_comparator.cc:157] Difference at 22: 0.74902, expected 0.0333384\n",
      "E0000 00:00:1748694709.719406    3239 buffer_comparator.cc:157] Difference at 23: 0.756863, expected 0.0595043\n",
      "E0000 00:00:1748694709.719408    3239 buffer_comparator.cc:157] Difference at 24: 0.835294, expected 0.0457344\n",
      "E0000 00:00:1748694709.719410    3239 buffer_comparator.cc:157] Difference at 25: 0.768627, expected 0.03394\n",
      "2025-05-31 14:31:49.719415: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.720662    3239 buffer_comparator.cc:157] Difference at 16: 0.854902, expected 0.0405081\n",
      "E0000 00:00:1748694709.720701    3239 buffer_comparator.cc:157] Difference at 17: 0.831373, expected 0.0446389\n",
      "E0000 00:00:1748694709.720709    3239 buffer_comparator.cc:157] Difference at 18: 0.854902, expected 0.0332528\n",
      "E0000 00:00:1748694709.720712    3239 buffer_comparator.cc:157] Difference at 19: 0.827451, expected 0.0329159\n",
      "E0000 00:00:1748694709.720715    3239 buffer_comparator.cc:157] Difference at 20: 0.823529, expected 0.0301345\n",
      "E0000 00:00:1748694709.720717    3239 buffer_comparator.cc:157] Difference at 21: 0.784314, expected 0.0431783\n",
      "E0000 00:00:1748694709.720719    3239 buffer_comparator.cc:157] Difference at 22: 0.74902, expected 0.0333384\n",
      "E0000 00:00:1748694709.720721    3239 buffer_comparator.cc:157] Difference at 23: 0.756863, expected 0.0595043\n",
      "E0000 00:00:1748694709.720723    3239 buffer_comparator.cc:157] Difference at 24: 0.835294, expected 0.0457344\n",
      "E0000 00:00:1748694709.720726    3239 buffer_comparator.cc:157] Difference at 25: 0.768627, expected 0.03394\n",
      "2025-05-31 14:31:49.720730: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.721897    3239 buffer_comparator.cc:157] Difference at 64: 0.176471, expected 0.0425131\n",
      "E0000 00:00:1748694709.721930    3239 buffer_comparator.cc:157] Difference at 66: 0.560784, expected 0.0165338\n",
      "E0000 00:00:1748694709.721938    3239 buffer_comparator.cc:157] Difference at 67: 0.462745, expected 0.0355858\n",
      "E0000 00:00:1748694709.721941    3239 buffer_comparator.cc:157] Difference at 68: 0.411765, expected 0.0354724\n",
      "E0000 00:00:1748694709.721943    3239 buffer_comparator.cc:157] Difference at 69: 0.772549, expected 0.0295664\n",
      "E0000 00:00:1748694709.721945    3239 buffer_comparator.cc:157] Difference at 70: 0.729412, expected 0.0552131\n",
      "E0000 00:00:1748694709.721948    3239 buffer_comparator.cc:157] Difference at 71: 0.627451, expected 0.040843\n",
      "E0000 00:00:1748694709.721950    3239 buffer_comparator.cc:157] Difference at 72: 0.811765, expected 0.0392232\n",
      "E0000 00:00:1748694709.721952    3239 buffer_comparator.cc:157] Difference at 73: 0.768627, expected 0.0342105\n",
      "E0000 00:00:1748694709.721954    3239 buffer_comparator.cc:157] Difference at 74: 0.662745, expected 0.0368887\n",
      "2025-05-31 14:31:49.721958: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.723226    3239 buffer_comparator.cc:157] Difference at 64: 0.176471, expected 0.0425131\n",
      "E0000 00:00:1748694709.723260    3239 buffer_comparator.cc:157] Difference at 66: 0.560784, expected 0.0165338\n",
      "E0000 00:00:1748694709.723268    3239 buffer_comparator.cc:157] Difference at 67: 0.462745, expected 0.0355858\n",
      "E0000 00:00:1748694709.723270    3239 buffer_comparator.cc:157] Difference at 68: 0.411765, expected 0.0354724\n",
      "E0000 00:00:1748694709.723273    3239 buffer_comparator.cc:157] Difference at 69: 0.772549, expected 0.0295664\n",
      "E0000 00:00:1748694709.723275    3239 buffer_comparator.cc:157] Difference at 70: 0.729412, expected 0.0552131\n",
      "E0000 00:00:1748694709.723277    3239 buffer_comparator.cc:157] Difference at 71: 0.627451, expected 0.040843\n",
      "E0000 00:00:1748694709.723280    3239 buffer_comparator.cc:157] Difference at 72: 0.811765, expected 0.0392232\n",
      "E0000 00:00:1748694709.723282    3239 buffer_comparator.cc:157] Difference at 73: 0.768627, expected 0.0342105\n",
      "E0000 00:00:1748694709.723284    3239 buffer_comparator.cc:157] Difference at 74: 0.662745, expected 0.0368887\n",
      "2025-05-31 14:31:49.723288: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.725487    3239 buffer_comparator.cc:157] Difference at 64: 0.176471, expected 0.0425131\n",
      "E0000 00:00:1748694709.725523    3239 buffer_comparator.cc:157] Difference at 66: 0.560784, expected 0.0165338\n",
      "E0000 00:00:1748694709.725531    3239 buffer_comparator.cc:157] Difference at 67: 0.462745, expected 0.0355858\n",
      "E0000 00:00:1748694709.725533    3239 buffer_comparator.cc:157] Difference at 68: 0.411765, expected 0.0354724\n",
      "E0000 00:00:1748694709.725536    3239 buffer_comparator.cc:157] Difference at 69: 0.772549, expected 0.0295664\n",
      "E0000 00:00:1748694709.725538    3239 buffer_comparator.cc:157] Difference at 70: 0.729412, expected 0.0552131\n",
      "E0000 00:00:1748694709.725540    3239 buffer_comparator.cc:157] Difference at 71: 0.627451, expected 0.040843\n",
      "E0000 00:00:1748694709.725543    3239 buffer_comparator.cc:157] Difference at 72: 0.811765, expected 0.0392232\n",
      "E0000 00:00:1748694709.725545    3239 buffer_comparator.cc:157] Difference at 73: 0.768627, expected 0.0342105\n",
      "E0000 00:00:1748694709.725547    3239 buffer_comparator.cc:157] Difference at 74: 0.662745, expected 0.0368887\n",
      "2025-05-31 14:31:49.725551: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.726919    3239 buffer_comparator.cc:157] Difference at 128: 0.72549, expected 0.0491834\n",
      "E0000 00:00:1748694709.726955    3239 buffer_comparator.cc:157] Difference at 129: 0.733333, expected 0.0406802\n",
      "E0000 00:00:1748694709.726964    3239 buffer_comparator.cc:157] Difference at 130: 0.72549, expected 0.0464702\n",
      "E0000 00:00:1748694709.726966    3239 buffer_comparator.cc:157] Difference at 131: 0.698039, expected 0.0303388\n",
      "E0000 00:00:1748694709.726969    3239 buffer_comparator.cc:157] Difference at 132: 0.717647, expected 0.0290469\n",
      "E0000 00:00:1748694709.726971    3239 buffer_comparator.cc:157] Difference at 133: 0.721569, expected 0.0347244\n",
      "E0000 00:00:1748694709.726973    3239 buffer_comparator.cc:157] Difference at 134: 0.701961, expected 0.0438591\n",
      "E0000 00:00:1748694709.726975    3239 buffer_comparator.cc:157] Difference at 135: 0.721569, expected 0.0357517\n",
      "E0000 00:00:1748694709.726977    3239 buffer_comparator.cc:157] Difference at 136: 0.729412, expected 0.0300613\n",
      "E0000 00:00:1748694709.726979    3239 buffer_comparator.cc:157] Difference at 137: 0.721569, expected 0.0412246\n",
      "2025-05-31 14:31:49.726984: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.728207    3239 buffer_comparator.cc:157] Difference at 128: 0.72549, expected 0.0491834\n",
      "E0000 00:00:1748694709.728243    3239 buffer_comparator.cc:157] Difference at 129: 0.733333, expected 0.0406802\n",
      "E0000 00:00:1748694709.728251    3239 buffer_comparator.cc:157] Difference at 130: 0.72549, expected 0.0464702\n",
      "E0000 00:00:1748694709.728253    3239 buffer_comparator.cc:157] Difference at 131: 0.698039, expected 0.0303388\n",
      "E0000 00:00:1748694709.728256    3239 buffer_comparator.cc:157] Difference at 132: 0.717647, expected 0.0290469\n",
      "E0000 00:00:1748694709.728258    3239 buffer_comparator.cc:157] Difference at 133: 0.721569, expected 0.0347244\n",
      "E0000 00:00:1748694709.728260    3239 buffer_comparator.cc:157] Difference at 134: 0.701961, expected 0.0438591\n",
      "E0000 00:00:1748694709.728262    3239 buffer_comparator.cc:157] Difference at 135: 0.721569, expected 0.0357517\n",
      "E0000 00:00:1748694709.728264    3239 buffer_comparator.cc:157] Difference at 136: 0.729412, expected 0.0300613\n",
      "E0000 00:00:1748694709.728266    3239 buffer_comparator.cc:157] Difference at 137: 0.721569, expected 0.0412246\n",
      "2025-05-31 14:31:49.728271: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.729441    3239 buffer_comparator.cc:157] Difference at 128: 0.72549, expected 0.0491834\n",
      "E0000 00:00:1748694709.729480    3239 buffer_comparator.cc:157] Difference at 129: 0.733333, expected 0.0406802\n",
      "E0000 00:00:1748694709.729488    3239 buffer_comparator.cc:157] Difference at 130: 0.72549, expected 0.0464702\n",
      "E0000 00:00:1748694709.729491    3239 buffer_comparator.cc:157] Difference at 131: 0.698039, expected 0.0303388\n",
      "E0000 00:00:1748694709.729493    3239 buffer_comparator.cc:157] Difference at 132: 0.717647, expected 0.0290469\n",
      "E0000 00:00:1748694709.729495    3239 buffer_comparator.cc:157] Difference at 133: 0.721569, expected 0.0347244\n",
      "E0000 00:00:1748694709.729497    3239 buffer_comparator.cc:157] Difference at 134: 0.701961, expected 0.0438591\n",
      "E0000 00:00:1748694709.729500    3239 buffer_comparator.cc:157] Difference at 135: 0.721569, expected 0.0357517\n",
      "E0000 00:00:1748694709.729502    3239 buffer_comparator.cc:157] Difference at 136: 0.729412, expected 0.0300613\n",
      "E0000 00:00:1748694709.729504    3239 buffer_comparator.cc:157] Difference at 137: 0.721569, expected 0.0412246\n",
      "2025-05-31 14:31:49.729508: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.730732    3239 buffer_comparator.cc:157] Difference at 128: 0.72549, expected 0.0491834\n",
      "E0000 00:00:1748694709.730761    3239 buffer_comparator.cc:157] Difference at 129: 0.733333, expected 0.0406802\n",
      "E0000 00:00:1748694709.730769    3239 buffer_comparator.cc:157] Difference at 130: 0.72549, expected 0.0464702\n",
      "E0000 00:00:1748694709.730771    3239 buffer_comparator.cc:157] Difference at 131: 0.698039, expected 0.0303388\n",
      "E0000 00:00:1748694709.730774    3239 buffer_comparator.cc:157] Difference at 132: 0.717647, expected 0.0290469\n",
      "E0000 00:00:1748694709.730776    3239 buffer_comparator.cc:157] Difference at 133: 0.721569, expected 0.0347244\n",
      "E0000 00:00:1748694709.730778    3239 buffer_comparator.cc:157] Difference at 134: 0.701961, expected 0.0438591\n",
      "E0000 00:00:1748694709.730780    3239 buffer_comparator.cc:157] Difference at 135: 0.721569, expected 0.0357517\n",
      "E0000 00:00:1748694709.730782    3239 buffer_comparator.cc:157] Difference at 136: 0.729412, expected 0.0300613\n",
      "E0000 00:00:1748694709.730784    3239 buffer_comparator.cc:157] Difference at 137: 0.721569, expected 0.0412246\n",
      "2025-05-31 14:31:49.730789: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.731865    3239 buffer_comparator.cc:157] Difference at 128: 0.72549, expected 0.0491834\n",
      "E0000 00:00:1748694709.731894    3239 buffer_comparator.cc:157] Difference at 129: 0.733333, expected 0.0406802\n",
      "E0000 00:00:1748694709.731902    3239 buffer_comparator.cc:157] Difference at 130: 0.72549, expected 0.0464702\n",
      "E0000 00:00:1748694709.731904    3239 buffer_comparator.cc:157] Difference at 131: 0.698039, expected 0.0303388\n",
      "E0000 00:00:1748694709.731906    3239 buffer_comparator.cc:157] Difference at 132: 0.717647, expected 0.0290469\n",
      "E0000 00:00:1748694709.731909    3239 buffer_comparator.cc:157] Difference at 133: 0.721569, expected 0.0347244\n",
      "E0000 00:00:1748694709.731911    3239 buffer_comparator.cc:157] Difference at 134: 0.701961, expected 0.0438591\n",
      "E0000 00:00:1748694709.731913    3239 buffer_comparator.cc:157] Difference at 135: 0.721569, expected 0.0357517\n",
      "E0000 00:00:1748694709.731915    3239 buffer_comparator.cc:157] Difference at 136: 0.729412, expected 0.0300613\n",
      "E0000 00:00:1748694709.731918    3239 buffer_comparator.cc:157] Difference at 137: 0.721569, expected 0.0412246\n",
      "2025-05-31 14:31:49.731922: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.733006    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.733034    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.733042    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.733045    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.733047    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.733049    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.733052    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.733054    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.733056    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.733058    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.733062: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.734207    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.734235    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.734244    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.734246    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.734249    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.734251    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.734253    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.734255    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.734257    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.734259    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.734264: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.735267    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.735295    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.735304    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.735307    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.735309    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.735311    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.735313    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.735315    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.735317    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.735320    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.735324: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.736484    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.736518    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.736526    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.736530    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.736532    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.736534    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.736536    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.736538    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.736540    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.736543    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.736547: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.738748    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.738777    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.738786    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.738788    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.738790    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.738793    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.738795    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.738797    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.738799    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.738801    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.738806: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694709.740105    3239 buffer_comparator.cc:157] Difference at 258: 0.282353, expected 0.044248\n",
      "E0000 00:00:1748694709.740134    3239 buffer_comparator.cc:157] Difference at 261: 0.572549, expected 0.0549664\n",
      "E0000 00:00:1748694709.740142    3239 buffer_comparator.cc:157] Difference at 262: 0.470588, expected 0.0460557\n",
      "E0000 00:00:1748694709.740145    3239 buffer_comparator.cc:157] Difference at 263: 0.4, expected 0.0469499\n",
      "E0000 00:00:1748694709.740147    3239 buffer_comparator.cc:157] Difference at 264: 0.945098, expected 0.0439516\n",
      "E0000 00:00:1748694709.740149    3239 buffer_comparator.cc:157] Difference at 265: 0.886275, expected 0.0286385\n",
      "E0000 00:00:1748694709.740152    3239 buffer_comparator.cc:157] Difference at 266: 0.811765, expected 0.0471515\n",
      "E0000 00:00:1748694709.740154    3239 buffer_comparator.cc:157] Difference at 267: 0.909804, expected 0.0430619\n",
      "E0000 00:00:1748694709.740156    3239 buffer_comparator.cc:157] Difference at 268: 0.882353, expected 0.0395621\n",
      "E0000 00:00:1748694709.740158    3239 buffer_comparator.cc:157] Difference at 269: 0.815686, expected 0.0369171\n",
      "2025-05-31 14:31:49.740163: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5531 - sparse_categorical_accuracy: 0.2440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748694710.907286    3238 buffer_comparator.cc:157] Difference at 7: 458.155, expected 512.297\n",
      "E0000 00:00:1748694710.907331    3238 buffer_comparator.cc:157] Difference at 27: 462.24, expected 514.587\n",
      "E0000 00:00:1748694710.907340    3238 buffer_comparator.cc:157] Difference at 37: 458.431, expected 513.219\n",
      "2025-05-31 14:31:50.907350: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0000 00:00:1748694710.908770    3238 buffer_comparator.cc:157] Difference at 5: 599.737, expected 511.192\n",
      "E0000 00:00:1748694710.908798    3238 buffer_comparator.cc:157] Difference at 8: 608.787, expected 493.959\n",
      "E0000 00:00:1748694710.908806    3238 buffer_comparator.cc:157] Difference at 12: 565.24, expected 501.434\n",
      "E0000 00:00:1748694710.908809    3238 buffer_comparator.cc:157] Difference at 15: 600.974, expected 508.861\n",
      "E0000 00:00:1748694710.908812    3238 buffer_comparator.cc:157] Difference at 18: 613.172, expected 495.876\n",
      "E0000 00:00:1748694710.908814    3238 buffer_comparator.cc:157] Difference at 25: 606.094, expected 522.842\n",
      "E0000 00:00:1748694710.908816    3238 buffer_comparator.cc:157] Difference at 27: 446.966, expected 514.587\n",
      "E0000 00:00:1748694710.908818    3238 buffer_comparator.cc:157] Difference at 28: 610.331, expected 503.137\n",
      "E0000 00:00:1748694710.908821    3238 buffer_comparator.cc:157] Difference at 35: 590.29, expected 521.438\n",
      "E0000 00:00:1748694710.908823    3238 buffer_comparator.cc:157] Difference at 37: 460.001, expected 513.219\n",
      "2025-05-31 14:31:50.908827: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 2.5517 - sparse_categorical_accuracy: 0.2442 - val_loss: 1.8016 - val_sparse_categorical_accuracy: 0.3592\n",
      "Epoch 2/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.7927 - sparse_categorical_accuracy: 0.3608 - val_loss: 1.7377 - val_sparse_categorical_accuracy: 0.3732\n",
      "Epoch 3/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.7054 - sparse_categorical_accuracy: 0.3971 - val_loss: 1.6854 - val_sparse_categorical_accuracy: 0.4006\n",
      "Epoch 4/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6530 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.6098 - val_sparse_categorical_accuracy: 0.4262\n",
      "Epoch 5/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6034 - sparse_categorical_accuracy: 0.4277 - val_loss: 1.6451 - val_sparse_categorical_accuracy: 0.4136\n",
      "Epoch 6/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5861 - sparse_categorical_accuracy: 0.4403 - val_loss: 1.5864 - val_sparse_categorical_accuracy: 0.4472\n",
      "Epoch 7/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5431 - sparse_categorical_accuracy: 0.4538 - val_loss: 1.6234 - val_sparse_categorical_accuracy: 0.4314\n",
      "Epoch 8/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5253 - sparse_categorical_accuracy: 0.4554 - val_loss: 1.5664 - val_sparse_categorical_accuracy: 0.4608\n",
      "Epoch 9/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.5022 - sparse_categorical_accuracy: 0.4648 - val_loss: 1.6330 - val_sparse_categorical_accuracy: 0.4360\n",
      "Epoch 10/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.5082 - sparse_categorical_accuracy: 0.4648 - val_loss: 1.5862 - val_sparse_categorical_accuracy: 0.4674\n",
      "Epoch 11/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4794 - sparse_categorical_accuracy: 0.4742 - val_loss: 1.6366 - val_sparse_categorical_accuracy: 0.4488\n",
      "Epoch 12/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4709 - sparse_categorical_accuracy: 0.4752 - val_loss: 1.5862 - val_sparse_categorical_accuracy: 0.4756\n",
      "Epoch 13/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4526 - sparse_categorical_accuracy: 0.4838 - val_loss: 1.6724 - val_sparse_categorical_accuracy: 0.4302\n",
      "Epoch 14/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4515 - sparse_categorical_accuracy: 0.4845 - val_loss: 1.6343 - val_sparse_categorical_accuracy: 0.4674\n",
      "Epoch 15/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4464 - sparse_categorical_accuracy: 0.4904 - val_loss: 1.6241 - val_sparse_categorical_accuracy: 0.4810\n",
      "Epoch 16/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4281 - sparse_categorical_accuracy: 0.4945 - val_loss: 1.6588 - val_sparse_categorical_accuracy: 0.4640\n",
      "Epoch 17/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4127 - sparse_categorical_accuracy: 0.4987 - val_loss: 1.6868 - val_sparse_categorical_accuracy: 0.4534\n",
      "Epoch 18/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4322 - sparse_categorical_accuracy: 0.4927 - val_loss: 1.7391 - val_sparse_categorical_accuracy: 0.4602\n",
      "Epoch 19/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4028 - sparse_categorical_accuracy: 0.5053 - val_loss: 1.7288 - val_sparse_categorical_accuracy: 0.4608\n",
      "Epoch 20/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.4076 - sparse_categorical_accuracy: 0.5025 - val_loss: 1.7639 - val_sparse_categorical_accuracy: 0.4666\n",
      "Epoch 21/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3926 - sparse_categorical_accuracy: 0.5049 - val_loss: 1.7977 - val_sparse_categorical_accuracy: 0.4600\n",
      "Epoch 22/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3893 - sparse_categorical_accuracy: 0.5083 - val_loss: 1.7876 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 23/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3888 - sparse_categorical_accuracy: 0.5030 - val_loss: 1.8049 - val_sparse_categorical_accuracy: 0.4736\n",
      "Epoch 24/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3807 - sparse_categorical_accuracy: 0.5111 - val_loss: 1.8255 - val_sparse_categorical_accuracy: 0.4826\n",
      "Epoch 25/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3626 - sparse_categorical_accuracy: 0.5203 - val_loss: 1.8635 - val_sparse_categorical_accuracy: 0.4806\n",
      "Epoch 26/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3680 - sparse_categorical_accuracy: 0.5147 - val_loss: 1.8828 - val_sparse_categorical_accuracy: 0.4714\n",
      "Epoch 27/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3573 - sparse_categorical_accuracy: 0.5166 - val_loss: 1.9455 - val_sparse_categorical_accuracy: 0.4696\n",
      "Epoch 28/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3516 - sparse_categorical_accuracy: 0.5230 - val_loss: 1.9600 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 29/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.3458 - sparse_categorical_accuracy: 0.5239 - val_loss: 1.9866 - val_sparse_categorical_accuracy: 0.4712\n",
      "Epoch 30/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3566 - sparse_categorical_accuracy: 0.5162 - val_loss: 2.0230 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 31/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3498 - sparse_categorical_accuracy: 0.5247 - val_loss: 2.0654 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 32/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3374 - sparse_categorical_accuracy: 0.5258 - val_loss: 2.0528 - val_sparse_categorical_accuracy: 0.4884\n",
      "Epoch 33/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3204 - sparse_categorical_accuracy: 0.5332 - val_loss: 2.0714 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 34/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3268 - sparse_categorical_accuracy: 0.5294 - val_loss: 2.0915 - val_sparse_categorical_accuracy: 0.4810\n",
      "Epoch 35/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3363 - sparse_categorical_accuracy: 0.5269 - val_loss: 2.1853 - val_sparse_categorical_accuracy: 0.4876\n",
      "Epoch 36/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3291 - sparse_categorical_accuracy: 0.5301 - val_loss: 2.2418 - val_sparse_categorical_accuracy: 0.4806\n",
      "Epoch 37/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3042 - sparse_categorical_accuracy: 0.5375 - val_loss: 2.2753 - val_sparse_categorical_accuracy: 0.4858\n",
      "Epoch 38/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3219 - sparse_categorical_accuracy: 0.5310 - val_loss: 2.3130 - val_sparse_categorical_accuracy: 0.4830\n",
      "Epoch 39/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3148 - sparse_categorical_accuracy: 0.5313 - val_loss: 2.3932 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 40/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3047 - sparse_categorical_accuracy: 0.5349 - val_loss: 2.3579 - val_sparse_categorical_accuracy: 0.4874\n",
      "Epoch 41/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.3019 - sparse_categorical_accuracy: 0.5407 - val_loss: 2.4049 - val_sparse_categorical_accuracy: 0.4880\n",
      "Epoch 42/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2979 - sparse_categorical_accuracy: 0.5415 - val_loss: 2.4802 - val_sparse_categorical_accuracy: 0.4942\n",
      "Epoch 43/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2956 - sparse_categorical_accuracy: 0.5381 - val_loss: 2.5685 - val_sparse_categorical_accuracy: 0.4708\n",
      "Epoch 44/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2883 - sparse_categorical_accuracy: 0.5472 - val_loss: 2.5989 - val_sparse_categorical_accuracy: 0.4882\n",
      "Epoch 45/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.2926 - sparse_categorical_accuracy: 0.5425 - val_loss: 2.6691 - val_sparse_categorical_accuracy: 0.4958\n",
      "Epoch 46/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2842 - sparse_categorical_accuracy: 0.5468 - val_loss: 2.7284 - val_sparse_categorical_accuracy: 0.4764\n",
      "Epoch 47/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.2895 - sparse_categorical_accuracy: 0.5425 - val_loss: 2.7600 - val_sparse_categorical_accuracy: 0.4796\n",
      "Epoch 48/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.2759 - sparse_categorical_accuracy: 0.5490 - val_loss: 2.7489 - val_sparse_categorical_accuracy: 0.4990\n",
      "Epoch 49/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2738 - sparse_categorical_accuracy: 0.5486 - val_loss: 2.8998 - val_sparse_categorical_accuracy: 0.4840\n",
      "Epoch 50/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2640 - sparse_categorical_accuracy: 0.5532 - val_loss: 2.9515 - val_sparse_categorical_accuracy: 0.4944\n",
      "Epoch 51/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2756 - sparse_categorical_accuracy: 0.5473 - val_loss: 2.9946 - val_sparse_categorical_accuracy: 0.4804\n",
      "Epoch 52/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2801 - sparse_categorical_accuracy: 0.5476 - val_loss: 3.0251 - val_sparse_categorical_accuracy: 0.4890\n",
      "Epoch 53/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2563 - sparse_categorical_accuracy: 0.5541 - val_loss: 3.1596 - val_sparse_categorical_accuracy: 0.4894\n",
      "Epoch 54/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2804 - sparse_categorical_accuracy: 0.5490 - val_loss: 3.3019 - val_sparse_categorical_accuracy: 0.4738\n",
      "Epoch 55/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2723 - sparse_categorical_accuracy: 0.5488 - val_loss: 3.2805 - val_sparse_categorical_accuracy: 0.4988\n",
      "Epoch 56/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2639 - sparse_categorical_accuracy: 0.5515 - val_loss: 3.3558 - val_sparse_categorical_accuracy: 0.4854\n",
      "Epoch 57/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2575 - sparse_categorical_accuracy: 0.5543 - val_loss: 3.4557 - val_sparse_categorical_accuracy: 0.4902\n",
      "Epoch 58/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2552 - sparse_categorical_accuracy: 0.5558 - val_loss: 3.5376 - val_sparse_categorical_accuracy: 0.4886\n",
      "Epoch 59/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2489 - sparse_categorical_accuracy: 0.5549 - val_loss: 3.6746 - val_sparse_categorical_accuracy: 0.4748\n",
      "Epoch 60/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2489 - sparse_categorical_accuracy: 0.5550 - val_loss: 3.6851 - val_sparse_categorical_accuracy: 0.5018\n",
      "Epoch 61/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2444 - sparse_categorical_accuracy: 0.5626 - val_loss: 3.7739 - val_sparse_categorical_accuracy: 0.4962\n",
      "Epoch 62/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2471 - sparse_categorical_accuracy: 0.5610 - val_loss: 3.8895 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 63/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2374 - sparse_categorical_accuracy: 0.5614 - val_loss: 3.9596 - val_sparse_categorical_accuracy: 0.4846\n",
      "Epoch 64/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2446 - sparse_categorical_accuracy: 0.5595 - val_loss: 4.0926 - val_sparse_categorical_accuracy: 0.4852\n",
      "Epoch 65/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2531 - sparse_categorical_accuracy: 0.5545 - val_loss: 4.1647 - val_sparse_categorical_accuracy: 0.4772\n",
      "Epoch 66/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.2390 - sparse_categorical_accuracy: 0.5629 - val_loss: 4.3175 - val_sparse_categorical_accuracy: 0.4878\n",
      "Epoch 67/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.2408 - sparse_categorical_accuracy: 0.5537 - val_loss: 4.3745 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 68/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2340 - sparse_categorical_accuracy: 0.5611 - val_loss: 4.4524 - val_sparse_categorical_accuracy: 0.4866\n",
      "Epoch 69/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.2431 - sparse_categorical_accuracy: 0.5621 - val_loss: 4.5564 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 70/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2351 - sparse_categorical_accuracy: 0.5620 - val_loss: 4.6126 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 71/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2198 - sparse_categorical_accuracy: 0.5678 - val_loss: 4.7540 - val_sparse_categorical_accuracy: 0.4916\n",
      "Epoch 72/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2269 - sparse_categorical_accuracy: 0.5655 - val_loss: 4.8506 - val_sparse_categorical_accuracy: 0.4848\n",
      "Epoch 73/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2268 - sparse_categorical_accuracy: 0.5643 - val_loss: 5.0052 - val_sparse_categorical_accuracy: 0.4764\n",
      "Epoch 74/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2157 - sparse_categorical_accuracy: 0.5672 - val_loss: 4.9998 - val_sparse_categorical_accuracy: 0.4878\n",
      "Epoch 75/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2245 - sparse_categorical_accuracy: 0.5612 - val_loss: 5.1246 - val_sparse_categorical_accuracy: 0.4744\n",
      "Epoch 76/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2198 - sparse_categorical_accuracy: 0.5650 - val_loss: 5.3139 - val_sparse_categorical_accuracy: 0.4764\n",
      "Epoch 77/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2136 - sparse_categorical_accuracy: 0.5681 - val_loss: 5.4322 - val_sparse_categorical_accuracy: 0.4852\n",
      "Epoch 78/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2112 - sparse_categorical_accuracy: 0.5685 - val_loss: 5.4971 - val_sparse_categorical_accuracy: 0.4740\n",
      "Epoch 79/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2233 - sparse_categorical_accuracy: 0.5620 - val_loss: 5.6747 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 80/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2094 - sparse_categorical_accuracy: 0.5698 - val_loss: 5.7866 - val_sparse_categorical_accuracy: 0.4732\n",
      "Epoch 81/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2190 - sparse_categorical_accuracy: 0.5678 - val_loss: 5.7983 - val_sparse_categorical_accuracy: 0.4922\n",
      "Epoch 82/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2085 - sparse_categorical_accuracy: 0.5693 - val_loss: 5.9320 - val_sparse_categorical_accuracy: 0.4838\n",
      "Epoch 83/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1994 - sparse_categorical_accuracy: 0.5750 - val_loss: 6.0707 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 84/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2155 - sparse_categorical_accuracy: 0.5670 - val_loss: 6.1333 - val_sparse_categorical_accuracy: 0.4894\n",
      "Epoch 85/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.2089 - sparse_categorical_accuracy: 0.5706 - val_loss: 6.3201 - val_sparse_categorical_accuracy: 0.4962\n",
      "Epoch 86/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1926 - sparse_categorical_accuracy: 0.5749 - val_loss: 6.3450 - val_sparse_categorical_accuracy: 0.4820\n",
      "Epoch 87/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2093 - sparse_categorical_accuracy: 0.5704 - val_loss: 6.5521 - val_sparse_categorical_accuracy: 0.4948\n",
      "Epoch 88/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1905 - sparse_categorical_accuracy: 0.5778 - val_loss: 6.7864 - val_sparse_categorical_accuracy: 0.4306\n",
      "Epoch 89/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.2136 - sparse_categorical_accuracy: 0.5698 - val_loss: 6.7348 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 90/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1832 - sparse_categorical_accuracy: 0.5825 - val_loss: 6.9021 - val_sparse_categorical_accuracy: 0.4838\n",
      "Epoch 91/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1919 - sparse_categorical_accuracy: 0.5792 - val_loss: 7.0265 - val_sparse_categorical_accuracy: 0.4842\n",
      "Epoch 92/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1924 - sparse_categorical_accuracy: 0.5761 - val_loss: 7.2146 - val_sparse_categorical_accuracy: 0.4746\n",
      "Epoch 93/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1862 - sparse_categorical_accuracy: 0.5751 - val_loss: 7.2454 - val_sparse_categorical_accuracy: 0.4884\n",
      "Epoch 94/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1852 - sparse_categorical_accuracy: 0.5800 - val_loss: 7.4588 - val_sparse_categorical_accuracy: 0.4702\n",
      "Epoch 95/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1894 - sparse_categorical_accuracy: 0.5784 - val_loss: 7.5086 - val_sparse_categorical_accuracy: 0.4874\n",
      "Epoch 96/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1798 - sparse_categorical_accuracy: 0.5813 - val_loss: 7.6802 - val_sparse_categorical_accuracy: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ca27c627d10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = f'logs/width/5'\n",
    "model = NewDenseModelCifar(depth=1, width=512)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "parm_count = str(model.count_params())\n",
    "print(f'model with p={parm_count}')\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "earlystopping_callback = keras.callbacks.EarlyStopping(monitor='loss',patience=3) # stop if the model can not reduce the training loss further\n",
    "\n",
    "model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=200,\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback, earlystopping_callback]\n",
    ")\n",
    "#model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd94f6",
   "metadata": {},
   "source": [
    "Here are the results of different widths:\n",
    "```\n",
    "128, in log 1\n",
    "352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - loss: 1.3743 - sparse_categorical_accuracy: 0.5128 - val_loss: 1.5221 - val_sparse_categorical_accuracy: 0.4724\n",
    "```\n",
    "---\n",
    "```\n",
    "256, in log 2, spikes back up to 2.5779!\n",
    "352/352 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - loss: 1.6420 - sparse_categorical_accuracy: 0.4185 - val_loss: 1.9133 - val_sparse_categorical_accuracy: 0.3140\n",
    "```\n",
    "---\n",
    "```\n",
    "256, in log 3, spikes back 2.5936!\n",
    "352/352 ━━━━━━━━━━━━━━━━━━━━ 4s 12ms/step - loss: 1.8345 - sparse_categorical_accuracy: 0.3299 - val_loss: 2.0843 - val_sparse_categorical_accuracy: 0.2202\n",
    "```\n",
    "---\n",
    "```\n",
    "512, in log 4\n",
    "352/352 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step - loss: 0.9481 - sparse_categorical_accuracy: 0.6614 - val_loss: 1.6258 - val_sparse_categorical_accuracy: 0.4992\n",
    "```\n",
    "---\n",
    "```\n",
    "1024, in log 5\n",
    "352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 1.1798 - sparse_categorical_accuracy: 0.5813 - val_loss: 7.6802 - val_sparse_categorical_accuracy: 0.4754\n",
    "```\n",
    "---\n",
    "Lowest loss is achieved with 512 before early stopping it also has the best validation accuracy.\n",
    "512 seems to be a good compromise we will continue to use this in further models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37cbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Width values used as x-axis (each one represents a configuration)\n",
    "widths = [128, 256, 256, 512, 1024]\n",
    "\n",
    "# Corresponding training and validation metrics\n",
    "train_loss = [1.3743, 1.6420, 1.8345, 0.9481, 1.1798]\n",
    "val_loss   = [1.5221, 1.9133, 2.0843, 1.6258, 7.6802]\n",
    "\n",
    "train_acc = [0.5128, 0.4185, 0.3299, 0.6614, 0.5813]\n",
    "val_acc   = [0.4724, 0.3140, 0.2202, 0.4992, 0.4754]\n",
    "\n",
    "labels = ['128', '256', '256 2nd', '512', '1024']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(labels, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(labels, val_loss, label='Validation Loss', marker='s')\n",
    "plt.title('Loss vs Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(labels, train_acc, label='Training Accuracy', marker='o')\n",
    "plt.plot(labels, val_acc, label='Validation Accuracy', marker='s')\n",
    "plt.title('Accuracy vs Width')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82a4eb",
   "metadata": {},
   "source": [
    "# Depth Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with p=6568970\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_176 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_180 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_181 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_182 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_41 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_176 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,573,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_177 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_179 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_180 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_181 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_182 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_183 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_184 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_185 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_186 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,568,970</span> (25.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,568,970\u001b[0m (25.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,568,970</span> (25.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,568,970\u001b[0m (25.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m  1/352\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:23\u001b[0m 5s/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 15:12:17.792399: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_3', 488 bytes spill stores, 488 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 48 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_4', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3190 - sparse_categorical_accuracy: 0.0979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 15:12:21.289165: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_3', 488 bytes spill stores, 488 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 48 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_4', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 2.3190 - sparse_categorical_accuracy: 0.0979 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0972\n",
      "Epoch 2/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.3027 - sparse_categorical_accuracy: 0.0995 - val_loss: 2.3027 - val_sparse_categorical_accuracy: 0.0972\n",
      "Epoch 3/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3027 - sparse_categorical_accuracy: 0.1014 - val_loss: 2.3027 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 4/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.1024 - val_loss: 2.3027 - val_sparse_categorical_accuracy: 0.0996\n",
      "Epoch 5/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3027 - sparse_categorical_accuracy: 0.0961 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.0972\n",
      "Epoch 6/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0973 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 7/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0976 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 8/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.1004 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 9/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ca2565f6a80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = f'logs/depth/20'\n",
    "model = NewDenseModelCifar(depth=20, width=512)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "parm_count = str(model.count_params())\n",
    "print(f'model with p={parm_count}')\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "earlystopping_callback = keras.callbacks.EarlyStopping(monitor='loss',patience=3)\n",
    "\n",
    "model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=200,\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback, earlystopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b3681",
   "metadata": {},
   "source": [
    "now test depth:\n",
    "we use the width 512 as assessed from above.\n",
    "- 1, log 1, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - loss: 0.9448 - sparse_categorical_accuracy: 0.6660 - val_loss: 1.9839 - val_sparse_categorical_accuracy: 0.4580\n",
    "- 2, log 2, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.4801 - sparse_categorical_accuracy: 0.8248 - val_loss: 2.6287 - val_sparse_categorical_accuracy: 0.4858\n",
    "- 3, log 3, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9339 - val_loss: 4.0999 - val_sparse_categorical_accuracy: 0.4726\n",
    "- 4, log 4, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9081 - val_loss: 4.0175 - val_sparse_categorical_accuracy: 0.4784\n",
    "- 5, log 5, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.2083 - sparse_categorical_accuracy: 0.9299 - val_loss: 4.3488 - val_sparse_categorical_accuracy: 0.4582\n",
    "- 6, log 6, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9445 - val_loss: 3.6839 - val_sparse_categorical_accuracy: 0.4654\n",
    "- 7, log 7, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.1899 - sparse_categorical_accuracy: 0.9344 - val_loss: 3.5324 - val_sparse_categorical_accuracy: 0.4684\n",
    "- 8, log 8, 352/352 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - loss: 0.2374 - sparse_categorical_accuracy: 0.9196 - val_loss: 3.2557 - val_sparse_categorical_accuracy: 0.4732\n",
    "- 9, log 9, 352/352 ━━━━━━━━━━━━━━━━━━━━ 3s 8ms/step - loss: 0.2181 - sparse_categorical_accuracy: 0.9277 - val_loss: 3.7965 - val_sparse_categorical_accuracy: 0.4502\n",
    "- 10, log 10, 352/352 ━━━━━━━━━━━━━━━━━━━━ 3s 8ms/step - loss: 0.2848 - sparse_categorical_accuracy: 0.9049 - val_loss: 2.9121 - val_sparse_categorical_accuracy: 0.4476\n",
    "- 15, log 15, 352/352 ━━━━━━━━━━━━━━━━━━━━ 3s 9ms/step - loss: 1.6583 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.7290 - val_sparse_categorical_accuracy: 0.3768\n",
    "- 20, log 20, 352/352 ━━━━━━━━━━━━━━━━━━━━ 3s 8ms/step - loss: 2.3026 - sparse_categorical_accuracy: 0.0987 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.0920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "\n",
    "# Training and validation loss and accuracy\n",
    "train_loss = [0.9448, 0.4801, 0.1912, 0.2689, 0.2083, 0.1650, 0.1899, 0.2374, 0.2181, 0.2848, 1.6583, 2.3026]\n",
    "val_loss   = [1.9839, 2.6287, 4.0999, 4.0175, 4.3488, 3.6839, 3.5324, 3.2557, 3.7965, 2.9121, 1.7290, 2.3028]\n",
    "\n",
    "train_acc  = [0.6660, 0.8248, 0.9339, 0.9081, 0.9299, 0.9445, 0.9344, 0.9196, 0.9277, 0.9049, 0.3917, 0.0987]\n",
    "val_acc    = [0.4580, 0.4858, 0.4726, 0.4784, 0.4582, 0.4654, 0.4684, 0.4732, 0.4502, 0.4476, 0.3768, 0.0920]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(depths, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(depths, val_loss, label='Validation Loss', marker='s')\n",
    "plt.title('Loss vs Depth (Width=512)')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(depths)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(depths, train_acc, label='Training Accuracy', marker='o')\n",
    "plt.plot(depths, val_acc, label='Validation Accuracy', marker='s')\n",
    "plt.title('Accuracy vs Depth (Width=512)')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(depths)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65025b2",
   "metadata": {},
   "source": [
    "Depth of 10 seems to be resonable since it overfits with low training loss and comperatively low validation loss.\n",
    "It also has and comperatively high training accuracy. Validation accuraccy is low through all tested depths.\n",
    "After depth of 10 the training loss increases and the validation loss decreases while both training and validation accuracy tank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a09288",
   "metadata": {},
   "source": [
    "It indeed helps training but does not really improve validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11a88d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_536\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_536\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_24      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_308 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │ flatten_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_308[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_116         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_309 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_309[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_117         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_310 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_310[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_118         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_311 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_311[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_119         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_312 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_312[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_120         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_313 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_313[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_121         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_314 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_314[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_122         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_315 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_315[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_123         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_316 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_316[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_124         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_317 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_317[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_125         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3584</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_318 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,835,520</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_318[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_126         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_319 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_319[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_127         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_320 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_320[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_128         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_321 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_321[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_129         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_322 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_322[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_130         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_323 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_323[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_131         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_324 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_324[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_132         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_325 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_325[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_133         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_326 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_326[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_134         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_327 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_327[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_135         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3584</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_135[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_328 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">35,850</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_24      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_24[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_308 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,573,376\u001b[0m │ flatten_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_308[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_144 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_116         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_309 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_309[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_145 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_117         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_310 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_310[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_146 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_118         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_311 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_311[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_147 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_119         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_312 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_312[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_148 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_120         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_313 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_313[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_149 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_121         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_314 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_314[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_150 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_122         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_315 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_315[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_151 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_123         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_316 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_316[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_152 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_124         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_317 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_317[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_153 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_125         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3584\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_318 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,835,520\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_318[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_154 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_126         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_319 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_319[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_155 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_127         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_320 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_320[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_156 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_128         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_321 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_321[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_157 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_129         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_322 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_322[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_158 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_130         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_323 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_323[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_159 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_131         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_324 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_324[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_160 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_132         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_325 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_325[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_161 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_133         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_326 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_326[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_162 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_134         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_327 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_327[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_163 (\u001b[38;5;33mReLU\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_135         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3584\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout_135[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_328 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │     \u001b[38;5;34m35,850\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,213,514</span> (31.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,213,514\u001b[0m (31.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,193,034</span> (31.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,193,034\u001b[0m (31.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,480</span> (80.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,480\u001b[0m (80.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:10:51.507545: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 616 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-06-04 21:10:51.632199: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 612 bytes spill stores, 524 bytes spill loads\n",
      "\n",
      "2025-06-04 21:10:51.669578: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-06-04 21:10:52.015374: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 716 bytes spill stores, 592 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m348/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9938 - sparse_categorical_accuracy: 0.2906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:11:04.235919: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10944', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:04.257191: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10944', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:04.619183: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10944', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.050359: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11023', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.123997: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 680 bytes spill stores, 680 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.281461: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 428 bytes spill stores, 428 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.326923: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 432 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.338772: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 500 bytes spill stores, 500 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.402500: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 432 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.508283: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.511715: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.536523: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 144 bytes spill stores, 144 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.671541: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 432 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "2025-06-04 21:11:05.821541: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13232', 816 bytes spill stores, 816 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - loss: 1.9916 - sparse_categorical_accuracy: 0.2914 - val_loss: 2.0382 - val_sparse_categorical_accuracy: 0.3206\n",
      "Epoch 2/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.6512 - sparse_categorical_accuracy: 0.4129 - val_loss: 1.7215 - val_sparse_categorical_accuracy: 0.3758\n",
      "Epoch 3/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.5465 - sparse_categorical_accuracy: 0.4503 - val_loss: 1.7592 - val_sparse_categorical_accuracy: 0.3908\n",
      "Epoch 4/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.4604 - sparse_categorical_accuracy: 0.4825 - val_loss: 1.9064 - val_sparse_categorical_accuracy: 0.3598\n",
      "Epoch 5/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.4066 - sparse_categorical_accuracy: 0.5028 - val_loss: 1.6167 - val_sparse_categorical_accuracy: 0.4436\n",
      "Epoch 6/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.3436 - sparse_categorical_accuracy: 0.5245 - val_loss: 1.7656 - val_sparse_categorical_accuracy: 0.3928\n",
      "Epoch 7/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.3182 - sparse_categorical_accuracy: 0.5264 - val_loss: 1.7625 - val_sparse_categorical_accuracy: 0.4016\n",
      "Epoch 8/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.2566 - sparse_categorical_accuracy: 0.5571 - val_loss: 1.8165 - val_sparse_categorical_accuracy: 0.4064\n",
      "Epoch 9/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.2193 - sparse_categorical_accuracy: 0.5662 - val_loss: 1.5925 - val_sparse_categorical_accuracy: 0.4614\n",
      "Epoch 10/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.1693 - sparse_categorical_accuracy: 0.5889 - val_loss: 1.5783 - val_sparse_categorical_accuracy: 0.4504\n",
      "Epoch 11/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.1418 - sparse_categorical_accuracy: 0.5943 - val_loss: 1.4911 - val_sparse_categorical_accuracy: 0.4962\n",
      "Epoch 12/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.0843 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.6702 - val_sparse_categorical_accuracy: 0.4484\n",
      "Epoch 13/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 1.0552 - sparse_categorical_accuracy: 0.6304 - val_loss: 1.8292 - val_sparse_categorical_accuracy: 0.4364\n",
      "Epoch 14/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 1.0051 - sparse_categorical_accuracy: 0.6403 - val_loss: 1.6759 - val_sparse_categorical_accuracy: 0.4382\n",
      "Epoch 15/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.9907 - sparse_categorical_accuracy: 0.6482 - val_loss: 1.7199 - val_sparse_categorical_accuracy: 0.4572\n",
      "Epoch 16/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.9479 - sparse_categorical_accuracy: 0.6657 - val_loss: 1.6452 - val_sparse_categorical_accuracy: 0.4748\n",
      "Epoch 17/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.6805 - val_loss: 1.8594 - val_sparse_categorical_accuracy: 0.4558\n",
      "Epoch 18/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.8862 - sparse_categorical_accuracy: 0.6863 - val_loss: 1.6820 - val_sparse_categorical_accuracy: 0.4816\n",
      "Epoch 19/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.8430 - sparse_categorical_accuracy: 0.7019 - val_loss: 1.7748 - val_sparse_categorical_accuracy: 0.4842\n",
      "Epoch 20/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.7980 - sparse_categorical_accuracy: 0.7176 - val_loss: 1.8681 - val_sparse_categorical_accuracy: 0.4928\n",
      "Epoch 21/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.7975 - sparse_categorical_accuracy: 0.7182 - val_loss: 1.5909 - val_sparse_categorical_accuracy: 0.5084\n",
      "Epoch 22/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.7317 - sparse_categorical_accuracy: 0.7417 - val_loss: 1.7529 - val_sparse_categorical_accuracy: 0.4834\n",
      "Epoch 23/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.7218 - sparse_categorical_accuracy: 0.7427 - val_loss: 1.7843 - val_sparse_categorical_accuracy: 0.5106\n",
      "Epoch 24/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.6995 - sparse_categorical_accuracy: 0.7524 - val_loss: 1.8230 - val_sparse_categorical_accuracy: 0.4952\n",
      "Epoch 25/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.6703 - sparse_categorical_accuracy: 0.7649 - val_loss: 1.8133 - val_sparse_categorical_accuracy: 0.4840\n",
      "Epoch 26/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.6313 - sparse_categorical_accuracy: 0.7768 - val_loss: 1.8853 - val_sparse_categorical_accuracy: 0.5020\n",
      "Epoch 27/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.6201 - sparse_categorical_accuracy: 0.7813 - val_loss: 2.0244 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 28/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.6078 - sparse_categorical_accuracy: 0.7868 - val_loss: 1.8361 - val_sparse_categorical_accuracy: 0.5094\n",
      "Epoch 29/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.8014 - val_loss: 1.8885 - val_sparse_categorical_accuracy: 0.5044\n",
      "Epoch 30/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.8069 - val_loss: 1.7051 - val_sparse_categorical_accuracy: 0.5270\n",
      "Epoch 31/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5276 - sparse_categorical_accuracy: 0.8150 - val_loss: 2.0957 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 32/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8215 - val_loss: 2.1747 - val_sparse_categorical_accuracy: 0.4768\n",
      "Epoch 33/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5262 - sparse_categorical_accuracy: 0.8173 - val_loss: 2.1481 - val_sparse_categorical_accuracy: 0.4684\n",
      "Epoch 34/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5017 - sparse_categorical_accuracy: 0.8221 - val_loss: 1.9399 - val_sparse_categorical_accuracy: 0.4980\n",
      "Epoch 35/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.4677 - sparse_categorical_accuracy: 0.8392 - val_loss: 2.0980 - val_sparse_categorical_accuracy: 0.5076\n",
      "Epoch 36/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.8412 - val_loss: 2.0100 - val_sparse_categorical_accuracy: 0.5242\n",
      "Epoch 37/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8502 - val_loss: 2.1104 - val_sparse_categorical_accuracy: 0.5074\n",
      "Epoch 38/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8538 - val_loss: 2.1837 - val_sparse_categorical_accuracy: 0.4986\n",
      "Epoch 39/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8549 - val_loss: 2.3784 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 40/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.4074 - sparse_categorical_accuracy: 0.8597 - val_loss: 2.2009 - val_sparse_categorical_accuracy: 0.5098\n",
      "Epoch 41/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3880 - sparse_categorical_accuracy: 0.8654 - val_loss: 2.4365 - val_sparse_categorical_accuracy: 0.5014\n",
      "Epoch 42/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3924 - sparse_categorical_accuracy: 0.8615 - val_loss: 2.1875 - val_sparse_categorical_accuracy: 0.5184\n",
      "Epoch 43/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8742 - val_loss: 2.1491 - val_sparse_categorical_accuracy: 0.5172\n",
      "Epoch 44/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3591 - sparse_categorical_accuracy: 0.8758 - val_loss: 2.7299 - val_sparse_categorical_accuracy: 0.4760\n",
      "Epoch 45/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3584 - sparse_categorical_accuracy: 0.8769 - val_loss: 2.4648 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 46/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3371 - sparse_categorical_accuracy: 0.8836 - val_loss: 2.3876 - val_sparse_categorical_accuracy: 0.5128\n",
      "Epoch 47/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3376 - sparse_categorical_accuracy: 0.8840 - val_loss: 2.3360 - val_sparse_categorical_accuracy: 0.5160\n",
      "Epoch 48/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3264 - sparse_categorical_accuracy: 0.8872 - val_loss: 2.7283 - val_sparse_categorical_accuracy: 0.4824\n",
      "Epoch 49/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3162 - sparse_categorical_accuracy: 0.8913 - val_loss: 2.2618 - val_sparse_categorical_accuracy: 0.5022\n",
      "Epoch 50/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3020 - sparse_categorical_accuracy: 0.8953 - val_loss: 2.3648 - val_sparse_categorical_accuracy: 0.4968\n",
      "Epoch 51/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2958 - sparse_categorical_accuracy: 0.8983 - val_loss: 2.6192 - val_sparse_categorical_accuracy: 0.4916\n",
      "Epoch 52/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3117 - sparse_categorical_accuracy: 0.8972 - val_loss: 2.3297 - val_sparse_categorical_accuracy: 0.5122\n",
      "Epoch 53/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.9025 - val_loss: 2.4542 - val_sparse_categorical_accuracy: 0.5176\n",
      "Epoch 54/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2977 - sparse_categorical_accuracy: 0.8981 - val_loss: 2.6015 - val_sparse_categorical_accuracy: 0.5070\n",
      "Epoch 55/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8951 - val_loss: 2.6342 - val_sparse_categorical_accuracy: 0.4982\n",
      "Epoch 56/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2798 - sparse_categorical_accuracy: 0.9057 - val_loss: 2.5891 - val_sparse_categorical_accuracy: 0.5068\n",
      "Epoch 57/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2802 - sparse_categorical_accuracy: 0.9059 - val_loss: 2.7394 - val_sparse_categorical_accuracy: 0.4980\n",
      "Epoch 58/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9089 - val_loss: 2.7157 - val_sparse_categorical_accuracy: 0.5066\n",
      "Epoch 59/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.9130 - val_loss: 2.9423 - val_sparse_categorical_accuracy: 0.4784\n",
      "Epoch 60/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9074 - val_loss: 2.4917 - val_sparse_categorical_accuracy: 0.5228\n",
      "Epoch 61/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2477 - sparse_categorical_accuracy: 0.9163 - val_loss: 2.4417 - val_sparse_categorical_accuracy: 0.5316\n",
      "Epoch 62/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2428 - sparse_categorical_accuracy: 0.9187 - val_loss: 2.4123 - val_sparse_categorical_accuracy: 0.5280\n",
      "Epoch 63/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2337 - sparse_categorical_accuracy: 0.9223 - val_loss: 2.6446 - val_sparse_categorical_accuracy: 0.5128\n",
      "Epoch 64/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2564 - sparse_categorical_accuracy: 0.9144 - val_loss: 2.7734 - val_sparse_categorical_accuracy: 0.5044\n",
      "Epoch 65/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.9155 - val_loss: 2.4807 - val_sparse_categorical_accuracy: 0.5372\n",
      "Epoch 66/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.2287 - sparse_categorical_accuracy: 0.9225 - val_loss: 2.6386 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 67/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.2266 - sparse_categorical_accuracy: 0.9222 - val_loss: 2.6298 - val_sparse_categorical_accuracy: 0.5260\n",
      "Epoch 68/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9206 - val_loss: 2.5369 - val_sparse_categorical_accuracy: 0.5194\n",
      "Epoch 69/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2213 - sparse_categorical_accuracy: 0.9259 - val_loss: 2.6529 - val_sparse_categorical_accuracy: 0.5166\n",
      "Epoch 70/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.9262 - val_loss: 2.8925 - val_sparse_categorical_accuracy: 0.5114\n",
      "Epoch 71/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9264 - val_loss: 2.6566 - val_sparse_categorical_accuracy: 0.5148\n",
      "Epoch 72/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9283 - val_loss: 2.8203 - val_sparse_categorical_accuracy: 0.5042\n",
      "Epoch 73/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2291 - sparse_categorical_accuracy: 0.9242 - val_loss: 3.0681 - val_sparse_categorical_accuracy: 0.4990\n",
      "Epoch 74/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.2344 - sparse_categorical_accuracy: 0.9225 - val_loss: 2.6683 - val_sparse_categorical_accuracy: 0.5132\n",
      "Epoch 75/75\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.2061 - sparse_categorical_accuracy: 0.9319 - val_loss: 2.5908 - val_sparse_categorical_accuracy: 0.5242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e2e26ee6810>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_path = f'logs/512-20/skip-batchnorm-dropout_01'\n",
    "\n",
    "dropout = 0.1\n",
    "width = 512\n",
    "\n",
    "inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "flatten = keras.layers.Flatten()(inputs)\n",
    "\n",
    "x = keras.layers.Dense(512, activation=None)(flatten) \n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Concatenate(axis=1)([x, flatten])\n",
    "\n",
    "# 10\n",
    "\n",
    "x = keras.layers.Dense(512, activation=None)(x) \n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Dense(512, activation=None)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(dropout)(x)\n",
    "x = keras.layers.Concatenate(axis=1)([x, flatten])\n",
    "\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=75,\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4d198",
   "metadata": {},
   "source": [
    "# Final Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92998bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_val = 0.3\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "\n",
    "model.add(keras.layers.Dense(2048, activation=None)) # smooth off to 512\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(1024, activation=None)) # smooth off to 512\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "\n",
    "model.add(keras.layers.Dense(512, activation=None)) # 10x512 layers\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "\n",
    "model.add(keras.layers.Dense(512, activation=None)) # 10x512 layers\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.Dense(512, activation=None))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Dropout(dropout_val))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "model.save('saved_models/full/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b22f0e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_124         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,293,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_125         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_126         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_127         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_128         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_129         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_130         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_131         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_132         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_133         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_134         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_135         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_136         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_137         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_138         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_139         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_140         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_141         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_142         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_143         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_144         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_145         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_146         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_124         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │        \u001b[38;5;34m12,288\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m6,293,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_125         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_122 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_126         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_123 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_127         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_124 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_128         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_125 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_129         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_126 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_130         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_127 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_131         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_128 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_132         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_129 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_133         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_130 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_134         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_131 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_135         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_132 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_136         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_133 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_137         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_134 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_138         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_135 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_139         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_136 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_140         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_137 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_141         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_138 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_142         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_139 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_143         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_140 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_144         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_141 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_69 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_145         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_142 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_146         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_143 (\u001b[38;5;33mReLU\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_78 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,977,610</span> (53.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,977,610\u001b[0m (53.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,944,842</span> (53.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,944,842\u001b[0m (53.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> (128.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32,768\u001b[0m (128.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81292286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 59ms/step - loss: 1.0341 - sparse_categorical_accuracy: 0.6501 - val_loss: 1.4989 - val_sparse_categorical_accuracy: 0.5280\n",
      "Epoch 2/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.0160 - sparse_categorical_accuracy: 0.6533 - val_loss: 1.4971 - val_sparse_categorical_accuracy: 0.5308\n",
      "Epoch 3/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.9980 - sparse_categorical_accuracy: 0.6628 - val_loss: 1.4996 - val_sparse_categorical_accuracy: 0.5302\n",
      "Epoch 4/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.9910 - sparse_categorical_accuracy: 0.6648 - val_loss: 1.5106 - val_sparse_categorical_accuracy: 0.5272\n",
      "Epoch 5/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.9884 - sparse_categorical_accuracy: 0.6641 - val_loss: 1.5150 - val_sparse_categorical_accuracy: 0.5300\n",
      "Epoch 6/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: 0.9736 - sparse_categorical_accuracy: 0.6708 - val_loss: 1.5168 - val_sparse_categorical_accuracy: 0.5314\n",
      "Epoch 7/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.9604 - sparse_categorical_accuracy: 0.6736 - val_loss: 1.5298 - val_sparse_categorical_accuracy: 0.5214\n",
      "Epoch 8/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.9591 - sparse_categorical_accuracy: 0.6746 - val_loss: 1.5420 - val_sparse_categorical_accuracy: 0.5310\n",
      "Epoch 9/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.9407 - sparse_categorical_accuracy: 0.6825 - val_loss: 1.5709 - val_sparse_categorical_accuracy: 0.5202\n",
      "Epoch 10/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.9451 - sparse_categorical_accuracy: 0.6803 - val_loss: 1.5284 - val_sparse_categorical_accuracy: 0.5318\n"
     ]
    }
   ],
   "source": [
    "log_path = f'logs/final/normal-batchnorm-dropout_03_augmentation'\n",
    "loaded_model = keras.models.load_model(\"saved_models/full/model.keras\")\n",
    "loaded_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"saved_models/cnn/model2.keras\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_sparse_categorical_accuracy'\n",
    ")\n",
    "\n",
    "loaded_model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=70,\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback, checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53314a82",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with p=170122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_80          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_81          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_82          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_83          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_84          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_85          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_86          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_87          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_80          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_81          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_82          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_31 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_83          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_84          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_140 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_85          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_141 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_86          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_142 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_87          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,122</span> (664.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,122\u001b[0m (664.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">169,098</span> (660.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m169,098\u001b[0m (660.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - loss: 1.9635 - sparse_categorical_accuracy: 0.3126 - val_loss: 2.7269 - val_sparse_categorical_accuracy: 0.1804\n",
      "Epoch 2/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2848 - sparse_categorical_accuracy: 0.5342 - val_loss: 1.5745 - val_sparse_categorical_accuracy: 0.4632\n",
      "Epoch 3/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 1.0542 - sparse_categorical_accuracy: 0.6200 - val_loss: 1.9035 - val_sparse_categorical_accuracy: 0.4454\n",
      "Epoch 4/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.9145 - sparse_categorical_accuracy: 0.6763 - val_loss: 1.0188 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 5/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.8019 - sparse_categorical_accuracy: 0.7183 - val_loss: 1.1770 - val_sparse_categorical_accuracy: 0.5700\n",
      "Epoch 6/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.7491 - sparse_categorical_accuracy: 0.7355 - val_loss: 1.0299 - val_sparse_categorical_accuracy: 0.6476\n",
      "Epoch 7/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.7547 - val_loss: 1.0528 - val_sparse_categorical_accuracy: 0.6454\n",
      "Epoch 8/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6482 - sparse_categorical_accuracy: 0.7753 - val_loss: 1.3169 - val_sparse_categorical_accuracy: 0.5820\n",
      "Epoch 9/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6139 - sparse_categorical_accuracy: 0.7834 - val_loss: 0.9272 - val_sparse_categorical_accuracy: 0.6826\n",
      "Epoch 10/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.5782 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.9477 - val_sparse_categorical_accuracy: 0.6910\n",
      "Epoch 11/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.8129 - val_loss: 1.1108 - val_sparse_categorical_accuracy: 0.6334\n",
      "Epoch 12/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5202 - sparse_categorical_accuracy: 0.8151 - val_loss: 1.1184 - val_sparse_categorical_accuracy: 0.6442\n",
      "Epoch 13/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4784 - sparse_categorical_accuracy: 0.8326 - val_loss: 1.0129 - val_sparse_categorical_accuracy: 0.6632\n",
      "Epoch 14/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.8409 - val_loss: 0.8742 - val_sparse_categorical_accuracy: 0.7136\n",
      "Epoch 15/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4349 - sparse_categorical_accuracy: 0.8493 - val_loss: 1.0673 - val_sparse_categorical_accuracy: 0.6636\n",
      "Epoch 16/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4085 - sparse_categorical_accuracy: 0.8575 - val_loss: 0.9200 - val_sparse_categorical_accuracy: 0.7154\n",
      "Epoch 17/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3765 - sparse_categorical_accuracy: 0.8679 - val_loss: 1.1256 - val_sparse_categorical_accuracy: 0.6760\n",
      "Epoch 18/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8688 - val_loss: 1.1518 - val_sparse_categorical_accuracy: 0.6528\n",
      "Epoch 19/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3527 - sparse_categorical_accuracy: 0.8780 - val_loss: 1.1611 - val_sparse_categorical_accuracy: 0.6472\n",
      "Epoch 20/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3324 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.8583 - val_sparse_categorical_accuracy: 0.7306\n",
      "Epoch 21/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.3194 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.9682 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 22/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.8733 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 23/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2798 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.8838 - val_sparse_categorical_accuracy: 0.7396\n",
      "Epoch 24/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2757 - sparse_categorical_accuracy: 0.9043 - val_loss: 1.0140 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 25/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2618 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.9109 - val_sparse_categorical_accuracy: 0.7298\n",
      "Epoch 26/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2447 - sparse_categorical_accuracy: 0.9136 - val_loss: 1.0277 - val_sparse_categorical_accuracy: 0.7156\n",
      "Epoch 27/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2383 - sparse_categorical_accuracy: 0.9170 - val_loss: 1.0463 - val_sparse_categorical_accuracy: 0.7202\n",
      "Epoch 28/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2350 - sparse_categorical_accuracy: 0.9162 - val_loss: 0.9341 - val_sparse_categorical_accuracy: 0.7322\n",
      "Epoch 29/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2152 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.9324 - val_sparse_categorical_accuracy: 0.7412\n",
      "Epoch 30/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2039 - sparse_categorical_accuracy: 0.9285 - val_loss: 1.1586 - val_sparse_categorical_accuracy: 0.7080\n",
      "Epoch 31/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9317 - val_loss: 0.8897 - val_sparse_categorical_accuracy: 0.7650\n",
      "Epoch 32/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9355 - val_loss: 1.0042 - val_sparse_categorical_accuracy: 0.7490\n",
      "Epoch 33/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9339 - val_loss: 1.2481 - val_sparse_categorical_accuracy: 0.6930\n",
      "Epoch 34/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.9198 - val_sparse_categorical_accuracy: 0.7632\n",
      "Epoch 35/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9458 - val_loss: 1.1521 - val_sparse_categorical_accuracy: 0.7196\n",
      "Epoch 36/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1608 - sparse_categorical_accuracy: 0.9417 - val_loss: 1.2411 - val_sparse_categorical_accuracy: 0.7086\n",
      "Epoch 37/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1515 - sparse_categorical_accuracy: 0.9463 - val_loss: 1.1195 - val_sparse_categorical_accuracy: 0.7534\n",
      "Epoch 38/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1532 - sparse_categorical_accuracy: 0.9453 - val_loss: 1.0265 - val_sparse_categorical_accuracy: 0.7564\n",
      "Epoch 39/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9506 - val_loss: 1.2972 - val_sparse_categorical_accuracy: 0.7138\n",
      "Epoch 40/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9527 - val_loss: 1.1806 - val_sparse_categorical_accuracy: 0.7362\n",
      "Epoch 41/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.9799 - val_sparse_categorical_accuracy: 0.7724\n",
      "Epoch 42/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9550 - val_loss: 1.4921 - val_sparse_categorical_accuracy: 0.6908\n",
      "Epoch 43/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9566 - val_loss: 1.4507 - val_sparse_categorical_accuracy: 0.7072\n",
      "Epoch 44/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9568 - val_loss: 1.1008 - val_sparse_categorical_accuracy: 0.7534\n",
      "Epoch 45/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9575 - val_loss: 1.1815 - val_sparse_categorical_accuracy: 0.7518\n",
      "Epoch 46/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9581 - val_loss: 1.4072 - val_sparse_categorical_accuracy: 0.7186\n",
      "Epoch 47/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9612 - val_loss: 1.4669 - val_sparse_categorical_accuracy: 0.7056\n",
      "Epoch 48/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9619 - val_loss: 1.2637 - val_sparse_categorical_accuracy: 0.7358\n",
      "Epoch 49/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9656 - val_loss: 1.2631 - val_sparse_categorical_accuracy: 0.7370\n",
      "Epoch 50/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9616 - val_loss: 1.1787 - val_sparse_categorical_accuracy: 0.7562\n",
      "Epoch 51/200\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9655 - val_loss: 1.3468 - val_sparse_categorical_accuracy: 0.7288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x783f60762570>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = f'logs/cnn/initial_64-2_v5_d64-5'\n",
    "\n",
    "k_size = (4,4)\n",
    "convs = 64\n",
    "dense_width = 64\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(keras.layers.Conv2D(convs, k_size, padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.Conv2D(convs, k_size, padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.AvgPool2D(4,padding=\"same\"))\n",
    "model.add(keras.layers.Conv2D(convs, k_size, padding=\"same\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.ReLU())\n",
    "model.add(keras.layers.AvgPool2D(4,padding=\"same\"))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(keras.layers.Dense(dense_width, activation=\"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(dense_width, activation=\"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(dense_width, activation=\"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(dense_width, activation=\"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(dense_width, activation=\"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "parm_count = str(model.count_params())\n",
    "print(f'model with p={parm_count}')\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "earlystopping_callback = keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience=10) # stop if the model can not reduce the training loss further\n",
    "\n",
    "model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=200, # increase the epochs to see behaviour monitored in last test\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback,earlystopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360173a",
   "metadata": {},
   "source": [
    "# Final Residual CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb06ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,792\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_22 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_23 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_24 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_25 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_26 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m131,584\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_27 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m5,130\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,255,754</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,255,754\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,250,762</span> (8.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,250,762\u001b[0m (8.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,992</span> (19.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,992\u001b[0m (19.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def residual_block(x, filters, filter_size=(3,3), stride=1, l2=1e-3, dropout=0.1):\n",
    "    shortcut = x\n",
    "    x = keras.layers.Conv2D(filters, filter_size, strides=stride, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2), activation=None)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.SpatialDropout2D(dropout)(x)\n",
    " \n",
    "    x = keras.layers.Conv2D(filters, filter_size, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2), activation=None)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.SpatialDropout2D(dropout)(x)\n",
    "    \n",
    "    x = keras.layers.Conv2D(filters, filter_size, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2), activation=None)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.SpatialDropout2D(dropout)(x)\n",
    " \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = keras.layers.Conv2D(filters, (1, 1), strides=stride, padding=\"same\", kernel_regularizer=keras.regularizers.l2(l2), activation=None)(shortcut)\n",
    "        shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = keras.layers.add([x, shortcut])\n",
    "    return x\n",
    " \n",
    "inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=keras.regularizers.l2(3e-5), activation=None)(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.SpatialDropout2D(0.03)(x)\n",
    "\n",
    "x = residual_block(x, filters=64, l2=3e-5, dropout=0.05, filter_size=(3,3), stride=1)\n",
    "x = keras.layers.SpatialDropout2D(0.03)(x)\n",
    "\n",
    "x = residual_block(x, filters=128, l2=3e-5, dropout=0.05, filter_size=(3,3), stride=2)\n",
    "x = keras.layers.SpatialDropout2D(0.05)(x)\n",
    "\n",
    "x = residual_block(x, filters=256, l2=3e-5, dropout=0.1, filter_size=(3,3), stride=2)\n",
    "x = keras.layers.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(512, activation=None, kernel_regularizer=keras.regularizers.l2(5e-5))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('saved_models/cnn/model20.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcbbfb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     14\u001b[39m reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m8\u001b[39m, min_lr=\u001b[32m0.00001\u001b[39m)\n\u001b[32m     16\u001b[39m checkpoint_cb = keras.callbacks.ModelCheckpoint(\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msaved_models/cnn/model20.keras\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     19\u001b[39m     save_weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     20\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_sparse_categorical_accuracy\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:132\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m         )\n\u001b[32m    135\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    136\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:113\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_step_on_data\u001b[39m(data):\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     outputs = reduce_per_replica(\n\u001b[32m    115\u001b[39m         outputs,\n\u001b[32m    116\u001b[39m         \u001b[38;5;28mself\u001b[39m.distribute_strategy,\n\u001b[32m    117\u001b[39m         reduction=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[39m, in \u001b[36mStrategyBase.run\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope():\n\u001b[32m   1669\u001b[39m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[39m, in \u001b[36mStrategyExtendedV1.call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m   kwargs = {}\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[39m, in \u001b[36m_DefaultDistributionExtended._call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:57\u001b[39m, in \u001b[36mTensorFlowTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m         y_pred = \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/layers/layer.py:910\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    908\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    912\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    914\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/ops/operation.py:58\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     54\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     55\u001b[39m         call_fn,\n\u001b[32m     56\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     57\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/models/functional.py:183\u001b[39m, in \u001b[36mFunctional.call\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m             backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/ops/function.py:171\u001b[39m, in \u001b[36mFunction._run_through_graph\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    169\u001b[39m     outputs = call_fn(op, *args, **kwargs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     outputs = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/models/functional.py:643\u001b[39m, in \u001b[36moperation_fn.<locals>.call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    638\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[33m\"\u001b[39m\u001b[33m_call_has_training_arg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    639\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m operation._call_has_training_arg\n\u001b[32m    640\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m ):\n\u001b[32m    642\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m] = training\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/layers/layer.py:910\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    908\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    912\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    914\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/ops/operation.py:58\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     54\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     55\u001b[39m         call_fn,\n\u001b[32m     56\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     57\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/layers/normalization/batch_normalization.py:278\u001b[39m, in \u001b[36mBatchNormalization.call\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    276\u001b[39m     beta = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m outputs = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_normalization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.cast(outputs, \u001b[38;5;28mself\u001b[39m.compute_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/ops/nn.py:2205\u001b[39m, in \u001b[36mbatch_normalization\u001b[39m\u001b[34m(x, mean, variance, axis, offset, scale, epsilon)\u001b[39m\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x, mean, variance, offset, scale)):\n\u001b[32m   2201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BatchNorm(axis, epsilon).symbolic_call(\n\u001b[32m   2202\u001b[39m         x, mean, variance, offset, scale\n\u001b[32m   2203\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_normalization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:870\u001b[39m, in \u001b[36mbatch_normalization\u001b[39m\u001b[34m(x, mean, variance, axis, offset, scale, epsilon)\u001b[39m\n\u001b[32m    867\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    868\u001b[39m         scale = tf.reshape(scale, shape)\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_normalization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/ops/nn_impl.py:1488\u001b[39m, in \u001b[36mbatch_normalization\u001b[39m\u001b[34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[39m\n\u001b[32m   1484\u001b[39m   inv *= scale\n\u001b[32m   1485\u001b[39m \u001b[38;5;66;03m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001b[39;00m\n\u001b[32m   1486\u001b[39m \u001b[38;5;66;03m# the precise order of ops that are generated by the expression below.\u001b[39;00m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x * math_ops.cast(inv, x.dtype) + math_ops.cast(\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m     \u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43minv\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m -mean * inv, x.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/override_binary_operator.py:113\u001b[39m, in \u001b[36moverride_binary_operator_helper.<locals>.binary_op_wrapper\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    109\u001b[39m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[32m    110\u001b[39m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[32m    111\u001b[39m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[32m    112\u001b[39m   x, y = maybe_promote_tensors(x, y)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    115\u001b[39m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[32m    116\u001b[39m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[32m    120\u001b[39m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[32m    121\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[33m\"\u001b[39m\u001b[33m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m__\u001b[39m\u001b[33m\"\u001b[39m % op_name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/ops/tensor_math_operator_overrides.py:94\u001b[39m, in \u001b[36m_subtract_factory\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_subtract_factory\u001b[39m(x, y, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     92\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmath_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/ops/math_ops.py:545\u001b[39m, in \u001b[36msubtract\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmath.subtract\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msubtract\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    542\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.register_binary_elementwise_api\n\u001b[32m    543\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msubtract\u001b[39m(x, y, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/ops/gen_math_ops.py:12316\u001b[39m, in \u001b[36msub\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m  12314\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m  12315\u001b[39m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12316\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12317\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSub\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  12318\u001b[39m _result = _outputs[:]\n\u001b[32m  12319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/op_def_library.py:778\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m g.as_default(), ops.name_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[32m    777\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[43m_ExtractInputsAndAttrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_list_attr_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_type_attr_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                           \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[32m    782\u001b[39m                            default_type_attr_map, attrs)\n\u001b[32m    783\u001b[39m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/op_def_library.py:551\u001b[39m, in \u001b[36m_ExtractInputsAndAttrs\u001b[39m\u001b[34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[39m\n\u001b[32m    545\u001b[39m       values = ops.convert_to_tensor(\n\u001b[32m    546\u001b[39m           values,\n\u001b[32m    547\u001b[39m           name=input_arg.name,\n\u001b[32m    548\u001b[39m           as_ref=input_arg.is_ref,\n\u001b[32m    549\u001b[39m           preferred_dtype=default_dtype)\n\u001b[32m    550\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_arg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_arg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    558\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:736\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    735\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:164\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add_error_prefix\u001b[39m(msg, *, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m msg \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(value,\n\u001b[32m    165\u001b[39m             dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    166\u001b[39m             name=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    167\u001b[39m             as_ref=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    168\u001b[39m             preferred_dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    169\u001b[39m             accepted_result_types=(core.Symbol,)):\n\u001b[32m    170\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Converts `value` to a `Tensor` using registered conversion functions.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m \u001b[33;03m      value.\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    202\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loaded_model = None\n",
    "loaded_model = keras.models.load_model(\"saved_models/cnn/model20.keras\")\n",
    "loaded_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(),\n",
    "    ],\n",
    ")\n",
    "    \n",
    "log_path = f'logs/cnn/final_20-2'\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=0.00001)\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"saved_models/cnn/model20.keras\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_sparse_categorical_accuracy'\n",
    ")\n",
    "\n",
    "loaded_model.fit(\n",
    "    loader.train_dataset,\n",
    "    epochs=200,\n",
    "    validation_data=loader.valid_dataset,\n",
    "    callbacks = [tensorboard_callback, checkpoint_cb, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41d5b4",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14f17dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,792\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m131,584\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m5,130\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,144,204</span> (8.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,144,204\u001b[0m (8.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,139,594</span> (8.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,139,594\u001b[0m (8.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> (18.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,608\u001b[0m (18.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.7537 - sparse_categorical_accuracy: 0.8990\n",
      "Test Loss: 0.7438924312591553\n",
      "Test Accuracy: 0.8988999724388123\n"
     ]
    }
   ],
   "source": [
    "# Best = model18.keras\n",
    "model = keras.models.load_model('saved_models/cnn/model18.keras')\n",
    "model.summary()\n",
    "test_dataset = loader.test_dataset.batch(128)\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41ac135",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=saved_models/full/model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msaved_models/full/model.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m test_dataset = loader.test_dataset.batch(\u001b[32m128\u001b[39m)\n\u001b[32m      3\u001b[39m test_loss, test_accuracy = model.evaluate(test_dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cifar/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=saved_models/full/model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('saved_models/full/model.keras')\n",
    "test_dataset = loader.test_dataset.batch(128)\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
